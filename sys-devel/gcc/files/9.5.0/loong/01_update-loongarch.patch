diff --git a/gcc/combine.c b/gcc/combine.c
index 10c643797..929466d0a 100644
--- a/gcc/combine.c
+++ b/gcc/combine.c
@@ -7076,28 +7076,28 @@ simplify_set (rtx x)
      be undefined.  On machine where it is defined, this transformation is safe
      as long as M1 and M2 have the same number of words.  */
 
-  if (GET_CODE (src) == SUBREG && subreg_lowpart_p (src)
-      && !OBJECT_P (SUBREG_REG (src))
-      && (known_equal_after_align_up
-	  (GET_MODE_SIZE (GET_MODE (src)),
-	   GET_MODE_SIZE (GET_MODE (SUBREG_REG (src))),
-	   UNITS_PER_WORD))
-      && (WORD_REGISTER_OPERATIONS || !paradoxical_subreg_p (src))
-      && ! (REG_P (dest) && REGNO (dest) < FIRST_PSEUDO_REGISTER
-	    && !REG_CAN_CHANGE_MODE_P (REGNO (dest),
-				       GET_MODE (SUBREG_REG (src)),
-				       GET_MODE (src)))
-      && (REG_P (dest)
-	  || (GET_CODE (dest) == SUBREG
-	      && REG_P (SUBREG_REG (dest)))))
-    {
-      SUBST (SET_DEST (x),
-	     gen_lowpart (GET_MODE (SUBREG_REG (src)),
-				      dest));
-      SUBST (SET_SRC (x), SUBREG_REG (src));
-
-      src = SET_SRC (x), dest = SET_DEST (x);
-    }
+//  if (GET_CODE (src) == SUBREG && subreg_lowpart_p (src)
+//      && !OBJECT_P (SUBREG_REG (src))
+//      && (known_equal_after_align_up
+//	  (GET_MODE_SIZE (GET_MODE (src)),
+//	   GET_MODE_SIZE (GET_MODE (SUBREG_REG (src))),
+//	   UNITS_PER_WORD))
+//      && (WORD_REGISTER_OPERATIONS || !paradoxical_subreg_p (src))
+//      && ! (REG_P (dest) && REGNO (dest) < FIRST_PSEUDO_REGISTER
+//	    && !REG_CAN_CHANGE_MODE_P (REGNO (dest),
+//				       GET_MODE (SUBREG_REG (src)),
+//				       GET_MODE (src)))
+//      && (REG_P (dest)
+//	  || (GET_CODE (dest) == SUBREG
+//	      && REG_P (SUBREG_REG (dest)))))
+//    {
+//      SUBST (SET_DEST (x),
+//	     gen_lowpart (GET_MODE (SUBREG_REG (src)),
+//				      dest));
+//      SUBST (SET_SRC (x), SUBREG_REG (src));
+//
+//      src = SET_SRC (x), dest = SET_DEST (x);
+//    }
 
   /* If we have (set (cc0) (subreg ...)), we try to remove the subreg
      in SRC.  */
diff --git a/gcc/config.gcc b/gcc/config.gcc
index 88ddf0637..4c0d63545 100644
--- a/gcc/config.gcc
+++ b/gcc/config.gcc
@@ -180,7 +180,7 @@
 #			the --with-sysroot configure option or the
 #			--sysroot command line option is used this
 #			will be relative to the sysroot.
-# target_type_format_char 
+# target_type_format_char
 # 			The default character to be used for formatting
 #			the attribute in a
 #			.type symbol_name, ${t_t_f_c}<property>
@@ -2265,6 +2265,18 @@ loongarch*-*-linux*)
 	gcc_cv_initfini_array=yes
 	;;
 
+loongarch*-*-elf*)
+	tm_file="elfos.h newlib-stdint.h ${tm_file}"
+	tm_file="${tm_file} loongarch/elf.h loongarch/linux.h"
+	tmake_file="${tmake_file} loongarch/t-linux"
+	gnu_ld=yes
+	gas=yes
+
+	# Force .init_array support.  The configure script cannot always
+	# automatically detect that GAS supports it, yet we require it.
+	gcc_cv_initfini_array=yes
+	;;
+
 mips*-*-netbsd*)			# NetBSD/mips, either endian.
 	target_cpu_default="MASK_ABICALLS"
 	tm_file="elfos.h ${tm_file} mips/elf.h ${nbsd_tm_file} mips/netbsd.h"
@@ -4432,7 +4444,7 @@ case "${target}" in
 					exit 1
 					;;
 				esac
-		
+
 				if test "x$t" = x
 				then
 					t="{ \"$option\", \"$val\" }"
@@ -4611,15 +4623,14 @@ case "${target}" in
 		;;
 
 	loongarch*-*-*)
-		supported_defaults="abi arch tune fpu multilib-default"
+		supported_defaults="abi arch tune fpu simd multilib-default"
 
 		# Local variables
 		unset \
 			abi_pattern      abi_default    \
 			abiext_pattern   abiext_default \
 			arch_pattern     arch_default   \
-			fpu_pattern      fpu_default    \
-			tune_pattern     tune_default   \
+			fpu_pattern	 fpu_default \
 			triplet_os       triplet_abi
 
 		# Infer ABI from the triplet.
@@ -4636,7 +4647,7 @@ case "${target}" in
 			abi_pattern="lp64s"
 			triplet_abi="sf"
 			;;
-		loongarch64-*-*-*)
+		loongarch64-*-*)
 			abi_pattern="lp64[dfs]"
 			abi_default="lp64d"
 			triplet_abi=""
@@ -4652,8 +4663,9 @@ case "${target}" in
 
 		# Get the canonical triplet (multiarch specifier).
 		case ${target} in
-		  *-linux-gnu*)  triplet_os="linux-gnu";;
-		  *-linux-musl*) triplet_os="linux-musl";;
+		  *-linux-gnu*)	  triplet_os="linux-gnu";;
+		  *-linux-musl*)  triplet_os="linux-musl";;
+		  *-elf*)	  triplet_os="elf";;
 		  *)
 			  echo "Unsupported target ${target}." 1>&2
 			  exit 1
@@ -4665,18 +4677,13 @@ case "${target}" in
 
 		# Perform initial sanity checks on --with-* options.
 		case ${with_arch} in
-		"" | abi-default | loongarch64 | la[234]64) ;; # OK, append here.
+		"" | abi-default | loongarch64 | la[2346]64) ;; # OK, append here.
 		native)
 			if test x${host} != x${target}; then
 				echo "--with-arch=native is illegal for cross-compiler." 1>&2
 				exit 1
 			fi
 			;;
-		"")
-			echo "Please set a default value for \${with_arch}" \
-			     "according to your target triplet \"${target}\"." 1>&2
-			exit 1
-			;;
 		*)
 			echo "Unknown arch in --with-arch=$with_arch" 1>&2
 			exit 1
@@ -4716,6 +4723,25 @@ case "${target}" in
 			;;
 		esac
 
+		case ${with_simd} in
+		"" | none) ;;
+		lsx | lasx)  # OK, append here.
+			case ${with_fpu} in
+			64) ;;
+			"") with_fpu=64 ;;
+			*)
+				echo "--with-simd=${with_simd} conflicts with --with-fpu=${with_fpu}" 1>&2
+				exit 1
+				;;
+			esac
+			;;
+
+		*)
+			echo "Unknown SIMD extension in --with-simd=$with_simd" 1>&2
+			exit 1
+			;;
+		esac
+
 
 		# Set default value for with_abi.
 		case ${with_abi} in
@@ -4764,7 +4790,7 @@ case "${target}" in
 		case ${with_abi}/${with_abiext} in
 		lp64*/base)
 			# architectures that support lp64* ABI
-			arch_pattern="native|abi-default|loongarch64|la[234]64"
+			arch_pattern="native|abi-default|loongarch64|la[2346]64"
 			# default architecture for lp64* ABI
 			arch_default="abi-default"
 			;;
@@ -4839,7 +4865,7 @@ case "${target}" in
 		# Check default with_tune configuration using with_arch.
 		case ${with_arch} in
 		loongarch64)
-			tune_pattern="native|abi-default|loongarch64|la[234]64"
+			tune_pattern="native|abi-default|loongarch64|la[2346]64"
 			;;
 		*)
 			# By default, $with_tune == $with_arch
@@ -4848,7 +4874,7 @@ case "${target}" in
 		esac
 
 		case ${with_tune} in
-		"")	with_tune="none" ;;
+		"") ;; # OK
 		*)
 			if echo "${with_tune}" | grep -E "^${tune_pattern}$" > /dev/null; then
 				: # OK
@@ -4974,7 +5000,7 @@ case "${target}" in
 				arch)
 					# -march option
 					case ${component} in
-					abi-default | loongarch64 | la[234]64) # OK, append here.
+					abi-default | loongarch64 | la[2346]64) # OK, append here.
 						# Append -march spec for each multilib variant.
 						loongarch_multilib_list_make="${loongarch_multilib_list_make}/march=${component}"
 						;&
@@ -5541,9 +5567,6 @@ case ${target} in
 		# Architecture
 		tm_defines="${tm_defines} DEFAULT_CPU_ARCH=CPU_$(tr a-z- A-Z_ <<< ${with_arch})"
 
-		# Microarchitecture
-		tm_defines="${tm_defines} DEFAULT_CPU_TUNE=CPU_$(tr a-z- A-Z_ <<< ${with_tune})"
-
 		# Base ABI type
 		tm_defines="${tm_defines} DEFAULT_ABI_BASE=ABI_BASE_$(tr a-z- A-Z_ <<< ${with_abi})"
 
@@ -5552,13 +5575,25 @@ case ${target} in
 		base)      tm_defines="${tm_defines} DEFAULT_ABI_EXT=ABI_EXT_BASE" ;;
 		esac
 
+		# Microarchitecture
+		if test x${with_tune} != x; then
+		  tm_defines="${tm_defines} DEFAULT_CPU_TUNE=CPU_$(tr a-z- A-Z_ <<< ${with_tune})"
+		fi
+
 		# FPU adjustment
 		case ${with_fpu} in
-		none)    tm_defines="$tm_defines DEFAULT_ISA_EXT_FPU=ISA_EXT_NOFPU" ;;
+		none)    tm_defines="$tm_defines DEFAULT_ISA_EXT_FPU=ISA_EXT_NONE" ;;
 		32)      tm_defines="$tm_defines DEFAULT_ISA_EXT_FPU=ISA_EXT_FPU32" ;;
 		64)      tm_defines="$tm_defines DEFAULT_ISA_EXT_FPU=ISA_EXT_FPU64" ;;
 		esac
 
+		# SIMD extensions
+		case ${with_simd} in
+		none)    tm_defines="$tm_defines DEFAULT_ISA_EXT_SIMD=ISA_EXT_NONE" ;;
+		lsx)     tm_defines="$tm_defines DEFAULT_ISA_EXT_SIMD=ISA_EXT_SIMD_LSX" ;;
+		lasx)    tm_defines="$tm_defines DEFAULT_ISA_EXT_SIMD=ISA_EXT_SIMD_LASX" ;;
+		esac
+
 		tmake_file="loongarch/t-loongarch $tmake_file"
 		;;
 
diff --git a/gcc/config/loongarch/elf.h b/gcc/config/loongarch/elf.h
new file mode 100644
index 000000000..edb0e77d2
--- /dev/null
+++ b/gcc/config/loongarch/elf.h
@@ -0,0 +1,54 @@
+/* Definitions for LoongArch systems using GNU (glibc-based) userspace,
+   or other userspace with libc derived from glibc.
+   Copyright (C) 1998-2018 Free Software Foundation, Inc.
+
+This file is part of GCC.
+
+GCC is free software; you can redistribute it and/or modify
+it under the terms of the GNU General Public License as published by
+the Free Software Foundation; either version 3, or (at your option)
+any later version.
+
+GCC is distributed in the hope that it will be useful,
+but WITHOUT ANY WARRANTY; without even the implied warranty of
+MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+GNU General Public License for more details.
+
+You should have received a copy of the GNU General Public License
+along with GCC; see the file COPYING3.  If not see
+<http://www.gnu.org/licenses/>.  */
+
+/* Define the size of the wide character type.  */
+#undef WCHAR_TYPE
+#define WCHAR_TYPE "int"
+
+#undef WCHAR_TYPE_SIZE
+#define WCHAR_TYPE_SIZE 32
+
+
+/* GNU-specific SPEC definitions.  */
+#define GNU_USER_LINK_EMULATION "elf" ABI_GRLEN_SPEC "loongarch"
+
+#undef GNU_USER_TARGET_LINK_SPEC
+#define GNU_USER_TARGET_LINK_SPEC \
+  "%{shared} -m " GNU_USER_LINK_EMULATION
+
+
+/* Link against Newlib libraries, because the ELF backend assumes Newlib.
+   Handle the circular dependence between libc and libgloss. */
+#undef  LIB_SPEC
+#define LIB_SPEC "--start-group -lc %{!specs=nosys.specs:-lgloss} --end-group"
+
+#undef LINK_SPEC
+#define LINK_SPEC GNU_USER_TARGET_LINK_SPEC
+
+#undef  STARTFILE_SPEC
+#define STARTFILE_SPEC "crt0%O%s crtbegin%O%s"
+
+#undef  ENDFILE_SPEC
+#define ENDFILE_SPEC "crtend%O%s"
+
+#define NO_IMPLICIT_EXTERN_C 1
+#undef SUBTARGET_CC1_SPEC
+#define SUBTARGET_CC1_SPEC "%{profile:-p}"
+
diff --git a/gcc/config/loongarch/genopts/loongarch-strings b/gcc/config/loongarch/genopts/loongarch-strings
index 3de64a391..d79e2e791 100644
--- a/gcc/config/loongarch/genopts/loongarch-strings
+++ b/gcc/config/loongarch/genopts/loongarch-strings
@@ -28,6 +28,7 @@ STR_CPU_LOONGARCH64   loongarch64
 STR_CPU_LA464	      la464
 STR_CPU_LA364	      la364
 STR_CPU_LA264	      la264
+STR_CPU_LA664	      la664
 
 # Base architecture
 STR_ISA_BASE_LA64V100 la64
diff --git a/gcc/config/loongarch/genopts/loongarch.opt.in b/gcc/config/loongarch/genopts/loongarch.opt.in
index f054cfa45..463dfec77 100644
--- a/gcc/config/loongarch/genopts/loongarch.opt.in
+++ b/gcc/config/loongarch/genopts/loongarch.opt.in
@@ -26,6 +26,9 @@ config/loongarch/loongarch-opts.h
 HeaderInclude
 config/loongarch/loongarch-str.h
 
+TargetVariable
+unsigned int recip_mask = 0
+
 ; ISA related options
 ;; Base ISA
 Enum
@@ -35,7 +38,6 @@ Basic ISAs of LoongArch:
 EnumValue
 Enum(isa_base) String(@@STR_ISA_BASE_LA64V100@@) Value(ISA_BASE_LA64V100)
 
-
 ;; ISA extensions / adjustments
 Enum
 Name(isa_ext_fpu) Type(int)
@@ -84,7 +86,7 @@ Enum(isa_ext_simd) String(@@STR_ISA_EXT_LASX@@) Value(ISA_EXT_SIMD_LASX)
 
 m@@OPTSTR_ISA_EXT_SIMD@@=
 Target RejectNegative Joined ToLower Enum(isa_ext_simd) Var(la_opt_simd) Init(M_OPT_UNSET)
--msimd=SIMD	Generate code for the given SIMD extension.
+-m@@OPTSTR_ISA_EXT_SIMD@@=SIMD	Generate code for the given SIMD extension.
 
 m@@STR_ISA_EXT_LSX@@
 Target Driver Defer Var(la_deferred_options)
@@ -108,6 +110,9 @@ Enum(cpu_type) String(@@STR_CPU_ABI_DEFAULT@@) Value(CPU_ABI_DEFAULT)
 EnumValue
 Enum(cpu_type) String(@@STR_CPU_LOONGARCH64@@) Value(CPU_LOONGARCH64)
 
+EnumValue
+Enum(cpu_type) String(@@STR_CPU_LA664@@) Value(CPU_LA664)
+
 EnumValue
 Enum(cpu_type) String(@@STR_CPU_LA464@@) Value(CPU_LA464)
 
@@ -204,6 +209,14 @@ mmax-inline-memcpy-size=
 Target Joined RejectNegative UInteger Var(loongarch_max_inline_memcpy_size) Init(1024)
 -mmax-inline-memcpy-size=SIZE	Set the max size of memcpy to inline, default is 1024.
 
+mrecip
+Target Report RejectNegative Var(loongarch_recip)
+Generate reciprocals instead of divss and sqrtss.
+
+mrecip=
+Target Report RejectNegative Joined Var(loongarch_recip_name)
+Control generation of reciprocal estimates.
+
 ; The code model option names for -mcmodel.
 Enum
 Name(cmodel) Type(int)
diff --git a/gcc/config/loongarch/gnu-user.h b/gcc/config/loongarch/gnu-user.h
index 664dc9206..ccda49ad4 100644
--- a/gcc/config/loongarch/gnu-user.h
+++ b/gcc/config/loongarch/gnu-user.h
@@ -40,8 +40,10 @@ along with GCC; see the file COPYING3.  If not see
 #undef GNU_USER_TARGET_LINK_SPEC
 #define GNU_USER_TARGET_LINK_SPEC \
   "%{G*} %{shared} -m " GNU_USER_LINK_EMULATION \
-  "%{!shared: %{static} %{!static: %{rdynamic:-export-dynamic} " \
-  "-dynamic-linker " GNU_USER_DYNAMIC_LINKER "}}"
+  "%{!shared: %{static} %{!static: %{!static-pie: \
+  %{rdynamic:-export-dynamic} " \
+  "-dynamic-linker " GNU_USER_DYNAMIC_LINKER "}}} \
+  %{static-pie:-static -pie --no-dynamic-linker -z text}"
 
 
 /* Similar to standard Linux, but adding -ffast-math support.  */
diff --git a/gcc/config/loongarch/la464.md b/gcc/config/loongarch/la464.md
index 5a47e1a77..ba9fc433b 100644
--- a/gcc/config/loongarch/la464.md
+++ b/gcc/config/loongarch/la464.md
@@ -43,88 +43,88 @@
 ;; Describe instruction reservations.
 
 (define_insn_reservation "la464_arith" 1
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "arith,clz,const,logical,
 			move,nop,shift,signext,slt"))
   "la464_alu1 | la464_alu2")
 
 (define_insn_reservation "la464_branch" 1
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "branch,jump,call,condmove,trap"))
   "la464_alu1 | la464_alu2")
 
 (define_insn_reservation "la464_imul" 7
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "imul"))
   "la464_alu1 | la464_alu2")
 
 (define_insn_reservation "la464_idiv_si" 12
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (and (eq_attr "type" "idiv")
 	    (eq_attr "mode" "SI")))
   "la464_alu1 | la464_alu2")
 
 (define_insn_reservation "la464_idiv_di" 25
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (and (eq_attr "type" "idiv")
 	    (eq_attr "mode" "DI")))
   "la464_alu1 | la464_alu2")
 
 (define_insn_reservation "la464_load" 4
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "load"))
   "la464_mem1 | la464_mem2")
 
 (define_insn_reservation "la464_gpr_fp" 16
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "mftg,mgtf"))
   "la464_mem1")
 
 (define_insn_reservation "la464_fpload" 4
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "fpload"))
   "la464_mem1 | la464_mem2")
 
 (define_insn_reservation "la464_prefetch" 0
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "prefetch,prefetchx"))
   "la464_mem1 | la464_mem2")
 
 (define_insn_reservation "la464_store" 0
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "store,fpstore,fpidxstore"))
   "la464_mem1 | la464_mem2")
 
 (define_insn_reservation "la464_fadd" 4
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "fadd,fmul,fmadd"))
   "la464_falu1 | la464_falu2")
 
 (define_insn_reservation "la464_fcmp" 2
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "fabs,fcmp,fmove,fneg"))
   "la464_falu1 | la464_falu2")
 
 (define_insn_reservation "la464_fcvt" 4
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "fcvt"))
   "la464_falu1 | la464_falu2")
 
 (define_insn_reservation "la464_fdiv_sf" 12
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (and (eq_attr "type" "fdiv,frdiv,fsqrt,frsqrt")
 	    (eq_attr "mode" "SF")))
   "la464_falu1 | la464_falu2")
 
 (define_insn_reservation "la464_fdiv_df" 19
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (and (eq_attr "type" "fdiv,frdiv,fsqrt,frsqrt")
 	    (eq_attr "mode" "DF")))
   "la464_falu1 | la464_falu2")
 
 ;; Force single-dispatch for unknown or multi.
 (define_insn_reservation "la464_unknown" 1
-  (and (match_test "TARGET_uARCH_LA464")
+  (and (match_test "TARGET_uARCH_LA464 || TARGET_uARCH_LA664")
        (eq_attr "type" "unknown,multi,atomic,syncloop"))
   "la464_alu1 + la464_alu2 + la464_falu1
    + la464_falu2 + la464_mem1 + la464_mem2")
diff --git a/gcc/config/loongarch/lasx.md b/gcc/config/loongarch/lasx.md
index 7078c0840..af46e7219 100644
--- a/gcc/config/loongarch/lasx.md
+++ b/gcc/config/loongarch/lasx.md
@@ -479,6 +479,37 @@
    (V16HI "w")
    (V32QI "w")])
 
+(define_int_iterator FRINT256_S [UNSPEC_LASX_XVFRINTRP_S
+			       UNSPEC_LASX_XVFRINTRZ_S
+			       UNSPEC_LASX_XVFRINT 
+			       UNSPEC_LASX_XVFRINTRM_S])
+
+(define_int_iterator FRINT256_D [UNSPEC_LASX_XVFRINTRP_D
+			       UNSPEC_LASX_XVFRINTRZ_D
+			       UNSPEC_LASX_XVFRINT 
+			       UNSPEC_LASX_XVFRINTRM_D])
+
+(define_int_attr frint256_pattern_s
+  [(UNSPEC_LASX_XVFRINTRP_S  "ceil")
+   (UNSPEC_LASX_XVFRINTRZ_S  "btrunc")
+   (UNSPEC_LASX_XVFRINT	     "rint")
+   (UNSPEC_LASX_XVFRINTRM_S  "floor")])
+
+(define_int_attr frint256_pattern_d
+  [(UNSPEC_LASX_XVFRINTRP_D  "ceil")
+   (UNSPEC_LASX_XVFRINTRZ_D  "btrunc")
+   (UNSPEC_LASX_XVFRINT	     "rint")
+   (UNSPEC_LASX_XVFRINTRM_D  "floor")])
+
+(define_int_attr frint256_suffix
+  [(UNSPEC_LASX_XVFRINTRP_S  "rp")
+   (UNSPEC_LASX_XVFRINTRP_D  "rp")
+   (UNSPEC_LASX_XVFRINTRZ_S  "rz")
+   (UNSPEC_LASX_XVFRINTRZ_D  "rz")
+   (UNSPEC_LASX_XVFRINT	     "")
+   (UNSPEC_LASX_XVFRINTRM_S  "rm")
+   (UNSPEC_LASX_XVFRINTRM_D  "rm")])
+
 (define_expand "vec_init<mode><unitmode>"
   [(match_operand:LASX 0 "register_operand")
    (match_operand:LASX 1 "")]
@@ -488,6 +519,15 @@
   DONE;
 })
 
+(define_expand "vec_initv32qiv16qi"
+ [(match_operand:V32QI 0 "register_operand")
+  (match_operand:V16QI 1 "")]
+  "ISA_HAS_LASX"
+{
+  loongarch_expand_vector_group_init (operands[0], operands[1]);
+  DONE;
+})
+
 ;; FIXME: Delete.
 (define_insn "vec_pack_trunc_<mode>"
    [(set (match_operand:<VHSMODE256> 0 "register_operand" "=f")
@@ -507,10 +547,12 @@
 	(float_extend:V4DF
 	  (vec_select:V4SF
 	    (match_operand:V8SF 1 "register_operand" "f")
-	    (match_dup 2))))]
+	    (parallel [(const_int 4) (const_int 5)
+                   (const_int 6) (const_int 7)]))))]
   "ISA_HAS_LASX"
 {
-  operands[2] = loongarch_lsx_vec_parallel_const_half (V8SFmode, true/*high_p*/);
+  loongarch_expand_fp_vec_unpack(operands, true/*high_p*/);
+  DONE;
 })
 
 (define_expand "vec_unpacks_lo_v8sf"
@@ -518,10 +560,12 @@
 	(float_extend:V4DF
 	  (vec_select:V4SF
 	    (match_operand:V8SF 1 "register_operand" "f")
-	    (match_dup 2))))]
+	    (parallel [(const_int 0) (const_int 1)
+                   (const_int 2) (const_int 3)]))))]
   "ISA_HAS_LASX"
 {
-  operands[2] = loongarch_lsx_vec_parallel_const_half (V8SFmode, false/*high_p*/);
+  loongarch_expand_fp_vec_unpack(operands, false/*high_p*/);
+  DONE;
 })
 
 (define_expand "vec_unpacks_hi_<mode>"
@@ -1133,7 +1177,25 @@
   [(set_attr "type" "simd_fmul")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "div<mode>3"
+(define_expand "div<mode>3"
+  [(set (match_operand:FLASX 0 "register_operand")
+    (div:FLASX (match_operand:FLASX 1 "register_operand")
+          (match_operand:FLASX 2 "register_operand")))]
+  "ISA_HAS_LASX"
+{
+  if (<MODE>mode == V8SFmode
+    && TARGET_RECIP_VEC_DIV
+    && optimize_insn_for_speed_p ()
+    && flag_finite_math_only && !flag_trapping_math
+    && flag_unsafe_math_optimizations)
+  {
+    loongarch_emit_swdivsf (operands[0], operands[1],
+           operands[2], V8SFmode);
+    DONE;
+  }
+})
+
+(define_insn "*div<mode>3"
   [(set (match_operand:FLASX 0 "register_operand" "=f")
 	(div:FLASX (match_operand:FLASX 1 "register_operand" "f")
 		  (match_operand:FLASX 2 "register_operand" "f")))]
@@ -1162,7 +1224,23 @@
   [(set_attr "type" "simd_fmadd")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "sqrt<mode>2"
+(define_expand "sqrt<mode>2"
+  [(set (match_operand:FLASX 0 "register_operand")
+    (sqrt:FLASX (match_operand:FLASX 1 "register_operand")))]
+  "ISA_HAS_LASX"
+{
+  if (<MODE>mode == V8SFmode
+      && TARGET_RECIP_VEC_SQRT
+      && flag_unsafe_math_optimizations
+      && optimize_insn_for_speed_p ()
+      && flag_finite_math_only && !flag_trapping_math)
+    {
+      loongarch_emit_swrsqrtsf (operands[0], operands[1], V8SFmode, 0);
+      DONE;
+    }
+})
+
+(define_insn "*sqrt<mode>2"
   [(set (match_operand:FLASX 0 "register_operand" "=f")
 	(sqrt:FLASX (match_operand:FLASX 1 "register_operand" "f")))]
   "ISA_HAS_LASX"
@@ -1561,6 +1639,15 @@
   [(set_attr "type" "simd_fdiv")
    (set_attr "mode" "<MODE>")])
 
+(define_insn "lasx_xvfrecipe_<flasxfmt>"
+  [(set (match_operand:FLASX 0 "register_operand" "=f")
+    (unspec:FLASX [(match_operand:FLASX 1 "register_operand" "f")]
+             UNSPEC_RECIPE))]
+  "ISA_HAS_LASX && flag_unsafe_math_optimizations"
+  "xvfrecipe.<flasxfmt>\t%u0,%u1"
+  [(set_attr "type" "simd_fdiv")
+   (set_attr "mode" "<MODE>")])
+
 (define_insn "lasx_xvfrint_<flasxfmt>"
   [(set (match_operand:FLASX 0 "register_operand" "=f")
 	(unspec:FLASX [(match_operand:FLASX 1 "register_operand" "f")]
@@ -1579,19 +1666,42 @@
   [(set_attr "type" "simd_fdiv")
    (set_attr "mode" "<MODE>")])
 
+
+(define_insn "lasx_xvfrsqrte_<flasxfmt>"
+  [(set (match_operand:FLASX 0 "register_operand" "=f")
+    (unspec:FLASX [(match_operand:FLASX 1 "register_operand" "f")]
+             UNSPEC_RSQRTE))]
+  "ISA_HAS_LASX && flag_unsafe_math_optimizations"
+  "xvfrsqrte.<flasxfmt>\t%u0,%u1"
+  [(set_attr "type" "simd_fdiv")
+   (set_attr "mode" "<MODE>")])
+
 (define_expand "rsqrt<mode>2"
   [(set (match_operand:FLASX 0 "register_operand" "=f")
     (unspec:FLASX [(match_operand:FLASX 1 "register_operand" "f")]
              UNSPEC_LASX_XVFRSQRT))]
-  "ISA_HAS_LASX && flag_unsafe_math_optimizations"
+  "ISA_HAS_LASX"
 {
-  if (<MODE>mode == V8SFmode)
-    loongarch_emit_swrsqrtsf (operands[0], operands[1], V8SFmode);
-  else
-    emit_insn (gen_lasx_xvfrsqrt_d (operands[0], operands[1]));
-  DONE;
+   if (<MODE>mode == V8SFmode
+       && TARGET_RECIP_VEC_RSQRT
+       && flag_unsafe_math_optimizations
+       && optimize_insn_for_speed_p ()
+       && flag_finite_math_only && !flag_trapping_math)
+     {
+       loongarch_emit_swrsqrtsf (operands[0], operands[1], V8SFmode, 1);
+       DONE;
+     }
 })
 
+(define_insn "*rsqrt<mode>2"
+  [(set (match_operand:FLASX 0 "register_operand" "=f")
+    (unspec:FLASX [(match_operand:FLASX 1 "register_operand" "f")]
+             UNSPEC_LASX_XVFRSQRT))]
+  "ISA_HAS_LASX"
+  "xvfrsqrt.<flasxfmt>\t%u0,%u1"
+  [(set_attr "type" "simd_fdiv")
+   (set_attr "mode" "<MODE>")])
+
 (define_insn "lasx_xvftint_s_<ilasxfmt>_<flasxfmt>"
   [(set (match_operand:<VIMODE256> 0 "register_operand" "=f")
 	(unspec:<VIMODE256> [(match_operand:FLASX 1 "register_operand" "f")]
@@ -2590,12 +2700,16 @@
 ;; Define for builtin function.
 (define_insn "lasx_xvfcvth_d_s"
   [(set (match_operand:V4DF 0 "register_operand" "=f")
-	(unspec:V4DF [(match_operand:V8SF 1 "register_operand" "f")]
-		     UNSPEC_LASX_XVFCVTH))]
+    (float_extend:V4DF
+    (vec_select:V4SF
+      (match_operand:V8SF 1 "register_operand" "f")
+      (parallel [(const_int 2) (const_int 3)
+                 (const_int 6) (const_int 7)]))))]
   "ISA_HAS_LASX"
   "xvfcvth.d.s\t%u0,%u1"
   [(set_attr "type" "simd_fcvt")
-   (set_attr "mode" "V4DF")])
+   (set_attr "mode" "V4DF")
+   (set_attr "length" "12")])
 
 ;; Define for gen insn.
 (define_insn "lasx_xvfcvth_d_insn"
@@ -2624,12 +2738,16 @@
 ;; Define for builtin function.
 (define_insn "lasx_xvfcvtl_d_s"
   [(set (match_operand:V4DF 0 "register_operand" "=f")
-	(unspec:V4DF [(match_operand:V8SF 1 "register_operand" "f")]
-		     UNSPEC_LASX_XVFCVTL))]
+    (float_extend:V4DF
+    (vec_select:V4SF
+      (match_operand:V8SF 1 "register_operand" "f")
+      (parallel [(const_int 0) (const_int 1)
+                 (const_int 4) (const_int 5)]))))]
   "ISA_HAS_LASX"
   "xvfcvtl.d.s\t%u0,%u1"
   [(set_attr "type" "simd_fcvt")
-   (set_attr "mode" "V4DF")])
+   (set_attr "mode" "V4DF")
+   (set_attr "length" "8")])
 
 ;; Define for gen insn.
 (define_insn "lasx_xvfcvtl_d_insn"
@@ -3362,8 +3480,8 @@
    (set_attr "mode" "V8SF")])
 
 (define_insn "lasx_xvfrintrne_s"
-  [(set (match_operand:V8SI 0 "register_operand" "=f")
-	(unspec:V8SI [(match_operand:V8SF 1 "register_operand" "f")]
+  [(set (match_operand:V8SF 0 "register_operand" "=f")
+	(unspec:V8SF [(match_operand:V8SF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRNE_S))]
   "ISA_HAS_LASX"
   "xvfrintrne.s\t%u0,%u1"
@@ -3371,8 +3489,8 @@
    (set_attr "mode" "V8SF")])
 
 (define_insn "lasx_xvfrintrne_d"
-  [(set (match_operand:V4DI 0 "register_operand" "=f")
-	(unspec:V4DI [(match_operand:V4DF 1 "register_operand" "f")]
+  [(set (match_operand:V4DF 0 "register_operand" "=f")
+	(unspec:V4DF [(match_operand:V4DF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRNE_D))]
   "ISA_HAS_LASX"
   "xvfrintrne.d\t%u0,%u1"
@@ -3380,8 +3498,8 @@
    (set_attr "mode" "V4DF")])
 
 (define_insn "lasx_xvfrintrz_s"
-  [(set (match_operand:V8SI 0 "register_operand" "=f")
-	(unspec:V8SI [(match_operand:V8SF 1 "register_operand" "f")]
+  [(set (match_operand:V8SF 0 "register_operand" "=f")
+	(unspec:V8SF [(match_operand:V8SF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRZ_S))]
   "ISA_HAS_LASX"
   "xvfrintrz.s\t%u0,%u1"
@@ -3389,8 +3507,8 @@
    (set_attr "mode" "V8SF")])
 
 (define_insn "lasx_xvfrintrz_d"
-  [(set (match_operand:V4DI 0 "register_operand" "=f")
-	(unspec:V4DI [(match_operand:V4DF 1 "register_operand" "f")]
+  [(set (match_operand:V4DF 0 "register_operand" "=f")
+	(unspec:V4DF [(match_operand:V4DF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRZ_D))]
   "ISA_HAS_LASX"
   "xvfrintrz.d\t%u0,%u1"
@@ -3398,8 +3516,8 @@
    (set_attr "mode" "V4DF")])
 
 (define_insn "lasx_xvfrintrp_s"
-  [(set (match_operand:V8SI 0 "register_operand" "=f")
-	(unspec:V8SI [(match_operand:V8SF 1 "register_operand" "f")]
+  [(set (match_operand:V8SF 0 "register_operand" "=f")
+	(unspec:V8SF [(match_operand:V8SF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRP_S))]
   "ISA_HAS_LASX"
   "xvfrintrp.s\t%u0,%u1"
@@ -3407,8 +3525,8 @@
    (set_attr "mode" "V8SF")])
 
 (define_insn "lasx_xvfrintrp_d"
-  [(set (match_operand:V4DI 0 "register_operand" "=f")
-	(unspec:V4DI [(match_operand:V4DF 1 "register_operand" "f")]
+  [(set (match_operand:V4DF 0 "register_operand" "=f")
+	(unspec:V4DF [(match_operand:V4DF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRP_D))]
   "ISA_HAS_LASX"
   "xvfrintrp.d\t%u0,%u1"
@@ -3416,8 +3534,8 @@
    (set_attr "mode" "V4DF")])
 
 (define_insn "lasx_xvfrintrm_s"
-  [(set (match_operand:V8SI 0 "register_operand" "=f")
-	(unspec:V8SI [(match_operand:V8SF 1 "register_operand" "f")]
+  [(set (match_operand:V8SF 0 "register_operand" "=f")
+	(unspec:V8SF [(match_operand:V8SF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRM_S))]
   "ISA_HAS_LASX"
   "xvfrintrm.s\t%u0,%u1"
@@ -3425,14 +3543,44 @@
    (set_attr "mode" "V8SF")])
 
 (define_insn "lasx_xvfrintrm_d"
-  [(set (match_operand:V4DI 0 "register_operand" "=f")
-	(unspec:V4DI [(match_operand:V4DF 1 "register_operand" "f")]
+  [(set (match_operand:V4DF 0 "register_operand" "=f")
+	(unspec:V4DF [(match_operand:V4DF 1 "register_operand" "f")]
 		     UNSPEC_LASX_XVFRINTRM_D))]
   "ISA_HAS_LASX"
   "xvfrintrm.d\t%u0,%u1"
   [(set_attr "type" "simd_shift")
    (set_attr "mode" "V4DF")])
 
+;; Vector versions of the floating-point frint patterns.
+;; Expands to btrunc, ceil, floor, rint.
+(define_insn "<frint256_pattern_s>v8sf2"
+ [(set (match_operand:V8SF 0 "register_operand" "=f")
+	(unspec:V8SF [(match_operand:V8SF 1 "register_operand" "f")]
+			 FRINT256_S))]
+  "ISA_HAS_LASX"
+  "xvfrint<frint256_suffix>.s\t%u0,%u1"
+  [(set_attr "type" "simd_shift")
+   (set_attr "mode" "V8SF")])
+
+(define_insn "<frint256_pattern_d>v4df2"
+ [(set (match_operand:V4DF 0 "register_operand" "=f")
+	(unspec:V4DF [(match_operand:V4DF 1 "register_operand" "f")]
+			 FRINT256_D))]
+  "ISA_HAS_LASX"
+  "xvfrint<frint256_suffix>.d\t%u0,%u1"
+  [(set_attr "type" "simd_shift")
+   (set_attr "mode" "V4DF")])
+
+;; Expands to round.
+(define_insn "round<mode>2"
+ [(set (match_operand:FLASX 0 "register_operand" "=f")
+	(unspec:FLASX [(match_operand:FLASX 1 "register_operand" "f")]
+			 UNSPEC_LASX_XVFRINT))]
+  "ISA_HAS_LASX"
+  "xvfrint.<flasxfmt>\t%u0,%u1"
+  [(set_attr "type" "simd_shift")
+   (set_attr "mode" "<MODE>")])
+
 ;; Offset load and broadcast
 (define_expand "lasx_xvldrepl_<lasxfmt_f>"
   [(match_operand:LASX 0 "register_operand")
@@ -5054,20 +5202,3 @@
         const0_rtx));
   DONE;
 })
-
-;; merge vec_unpacks_hi_v8sf/vec_unpacks_lo_v8sf
-(define_peephole
-  [(set (match_operand:V4DF 0 "register_operand")
-    (float_extend:V4DF (vec_select:V4SF
-                 (match_operand:V8SF 1 "register_operand")
-                 (parallel [(const_int 0) (const_int 1)
-                            (const_int 2) (const_int 3)]))))
-   (set (match_operand:V4DF 2 "register_operand")
-    (float_extend:V4DF (vec_select:V4SF
-                 (match_operand:V8SF 3 "register_operand")
-                 (parallel [(const_int 4) (const_int 5)
-                            (const_int 6) (const_int 7)]))))]
-  "ISA_HAS_LASX && rtx_equal_p (operands[1], operands[3])"
-{
-  return "xvpermi.d\t%u2,%u1,0xd8\n\txvfcvtl.d.s\t%u0,%u2\n\txvfcvth.d.s\t%u2,%u2";
-})
diff --git a/gcc/config/loongarch/lasxintrin.h b/gcc/config/loongarch/lasxintrin.h
index 9feaa5715..58f3047ac 100644
--- a/gcc/config/loongarch/lasxintrin.h
+++ b/gcc/config/loongarch/lasxintrin.h
@@ -3262,65 +3262,65 @@ __m256i __lasx_xvftintrnel_l_s(__m256 _1)
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V8SI, V8SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrne_s(__m256 _1)
+__m256 __lasx_xvfrintrne_s(__m256 _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrne_s((v8f32)_1);
+	return (__m256)__builtin_lasx_xvfrintrne_s((v8f32)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V4DI, V4DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrne_d(__m256d _1)
+__m256d __lasx_xvfrintrne_d(__m256d _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrne_d((v4f64)_1);
+	return (__m256d)__builtin_lasx_xvfrintrne_d((v4f64)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V8SI, V8SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrz_s(__m256 _1)
+__m256 __lasx_xvfrintrz_s(__m256 _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrz_s((v8f32)_1);
+	return (__m256)__builtin_lasx_xvfrintrz_s((v8f32)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V4DI, V4DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrz_d(__m256d _1)
+__m256d __lasx_xvfrintrz_d(__m256d _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrz_d((v4f64)_1);
+	return (__m256d)__builtin_lasx_xvfrintrz_d((v4f64)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V8SI, V8SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrp_s(__m256 _1)
+__m256 __lasx_xvfrintrp_s(__m256 _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrp_s((v8f32)_1);
+	return (__m256)__builtin_lasx_xvfrintrp_s((v8f32)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V4DI, V4DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrp_d(__m256d _1)
+__m256d __lasx_xvfrintrp_d(__m256d _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrp_d((v4f64)_1);
+	return (__m256d)__builtin_lasx_xvfrintrp_d((v4f64)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V8SI, V8SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrm_s(__m256 _1)
+__m256 __lasx_xvfrintrm_s(__m256 _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrm_s((v8f32)_1);
+	return (__m256)__builtin_lasx_xvfrintrm_s((v8f32)_1);
 }
 
 /* Assembly instruction format:          xd, xj.  */
 /* Data types in instruction templates:  V4DI, V4DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m256i __lasx_xvfrintrm_d(__m256d _1)
+__m256d __lasx_xvfrintrm_d(__m256d _1)
 {
-	return (__m256i)__builtin_lasx_xvfrintrm_d((v4f64)_1);
+	return (__m256d)__builtin_lasx_xvfrintrm_d((v4f64)_1);
 }
 
 /* Assembly instruction format:          xd, rj, si12.  */
diff --git a/gcc/config/loongarch/loongarch-builtins.c b/gcc/config/loongarch/loongarch-builtins.c
index eb2c42245..b326ec46c 100644
--- a/gcc/config/loongarch/loongarch-builtins.c
+++ b/gcc/config/loongarch/loongarch-builtins.c
@@ -1355,14 +1355,14 @@ static const struct loongarch_builtin_description loongarch_builtins[] = {
   LSX_BUILTIN (vftintrmh_l_s, LARCH_V2DI_FTYPE_V4SF),
   LSX_BUILTIN (vftintrnel_l_s, LARCH_V2DI_FTYPE_V4SF),
   LSX_BUILTIN (vftintrneh_l_s, LARCH_V2DI_FTYPE_V4SF),
-  LSX_BUILTIN (vfrintrne_s, LARCH_V4SI_FTYPE_V4SF),
-  LSX_BUILTIN (vfrintrne_d, LARCH_V2DI_FTYPE_V2DF),
-  LSX_BUILTIN (vfrintrz_s, LARCH_V4SI_FTYPE_V4SF),
-  LSX_BUILTIN (vfrintrz_d, LARCH_V2DI_FTYPE_V2DF),
-  LSX_BUILTIN (vfrintrp_s, LARCH_V4SI_FTYPE_V4SF),
-  LSX_BUILTIN (vfrintrp_d, LARCH_V2DI_FTYPE_V2DF),
-  LSX_BUILTIN (vfrintrm_s, LARCH_V4SI_FTYPE_V4SF),
-  LSX_BUILTIN (vfrintrm_d, LARCH_V2DI_FTYPE_V2DF),
+  LSX_BUILTIN (vfrintrne_s, LARCH_V4SF_FTYPE_V4SF),
+  LSX_BUILTIN (vfrintrne_d, LARCH_V2DF_FTYPE_V2DF),
+  LSX_BUILTIN (vfrintrz_s, LARCH_V4SF_FTYPE_V4SF),
+  LSX_BUILTIN (vfrintrz_d, LARCH_V2DF_FTYPE_V2DF),
+  LSX_BUILTIN (vfrintrp_s, LARCH_V4SF_FTYPE_V4SF),
+  LSX_BUILTIN (vfrintrp_d, LARCH_V2DF_FTYPE_V2DF),
+  LSX_BUILTIN (vfrintrm_s, LARCH_V4SF_FTYPE_V4SF),
+  LSX_BUILTIN (vfrintrm_d, LARCH_V2DF_FTYPE_V2DF),
   LSX_NO_TARGET_BUILTIN (vstelm_b, LARCH_VOID_FTYPE_V16QI_CVPOINTER_SI_UQI),
   LSX_NO_TARGET_BUILTIN (vstelm_h, LARCH_VOID_FTYPE_V8HI_CVPOINTER_SI_UQI),
   LSX_NO_TARGET_BUILTIN (vstelm_w, LARCH_VOID_FTYPE_V4SI_CVPOINTER_SI_UQI),
@@ -2068,14 +2068,14 @@ static const struct loongarch_builtin_description loongarch_builtins[] = {
   LASX_BUILTIN (xvftintrml_l_s, LARCH_V4DI_FTYPE_V8SF),
   LASX_BUILTIN (xvftintrneh_l_s, LARCH_V4DI_FTYPE_V8SF),
   LASX_BUILTIN (xvftintrnel_l_s, LARCH_V4DI_FTYPE_V8SF),
-  LASX_BUILTIN (xvfrintrne_s, LARCH_V8SI_FTYPE_V8SF),
-  LASX_BUILTIN (xvfrintrne_d, LARCH_V4DI_FTYPE_V4DF),
-  LASX_BUILTIN (xvfrintrz_s, LARCH_V8SI_FTYPE_V8SF),
-  LASX_BUILTIN (xvfrintrz_d, LARCH_V4DI_FTYPE_V4DF),
-  LASX_BUILTIN (xvfrintrp_s, LARCH_V8SI_FTYPE_V8SF),
-  LASX_BUILTIN (xvfrintrp_d, LARCH_V4DI_FTYPE_V4DF),
-  LASX_BUILTIN (xvfrintrm_s, LARCH_V8SI_FTYPE_V8SF),
-  LASX_BUILTIN (xvfrintrm_d, LARCH_V4DI_FTYPE_V4DF),
+  LASX_BUILTIN (xvfrintrne_s, LARCH_V8SF_FTYPE_V8SF),
+  LASX_BUILTIN (xvfrintrne_d, LARCH_V4DF_FTYPE_V4DF),
+  LASX_BUILTIN (xvfrintrz_s, LARCH_V8SF_FTYPE_V8SF),
+  LASX_BUILTIN (xvfrintrz_d, LARCH_V4DF_FTYPE_V4DF),
+  LASX_BUILTIN (xvfrintrp_s, LARCH_V8SF_FTYPE_V8SF),
+  LASX_BUILTIN (xvfrintrp_d, LARCH_V4DF_FTYPE_V4DF),
+  LASX_BUILTIN (xvfrintrm_s, LARCH_V8SF_FTYPE_V8SF),
+  LASX_BUILTIN (xvfrintrm_d, LARCH_V4DF_FTYPE_V4DF),
   LASX_BUILTIN (xvld, LARCH_V32QI_FTYPE_CVPOINTER_SI),
   LASX_NO_TARGET_BUILTIN (xvst, LARCH_VOID_FTYPE_V32QI_CVPOINTER_SI),
   LASX_NO_TARGET_BUILTIN (xvstelm_b, LARCH_VOID_FTYPE_V32QI_CVPOINTER_SI_UQI),
diff --git a/gcc/config/loongarch/loongarch-cpu.c b/gcc/config/loongarch/loongarch-cpu.c
index 09ef18672..d12bcd41b 100644
--- a/gcc/config/loongarch/loongarch-cpu.c
+++ b/gcc/config/loongarch/loongarch-cpu.c
@@ -100,6 +100,10 @@ fill_native_cpu_config (struct loongarch_target *tgt)
 
   switch (cpucfg_cache[0] & 0x00ffff00)
   {
+    case 0x0014d000:   /* LA664 */
+      native_cpu_type = CPU_LA664;
+      break;
+
     case 0x0014c000:   /* LA464 */
       native_cpu_type = CPU_LA464;
       break;
diff --git a/gcc/config/loongarch/loongarch-def.c b/gcc/config/loongarch/loongarch-def.c
index 0a25de750..dde7a5dba 100644
--- a/gcc/config/loongarch/loongarch-def.c
+++ b/gcc/config/loongarch/loongarch-def.c
@@ -30,6 +30,7 @@ loongarch_cpu_strings[N_TUNE_TYPES] = {
   [CPU_LA464]		  = STR_CPU_LA464,
   [CPU_LA364]		  = STR_CPU_LA364,
   [CPU_LA264]		  = STR_CPU_LA264,
+  [CPU_LA664]		  = STR_CPU_LA664,
 };
 
 struct loongarch_isa
@@ -54,6 +55,11 @@ loongarch_cpu_default_isa[N_ARCH_TYPES] = {
       .fpu = ISA_EXT_FPU64,
       .simd = ISA_EXT_SIMD_LSX,
   },
+  [CPU_LA664] = {
+      .base = ISA_BASE_LA64V100,
+      .fpu = ISA_EXT_FPU64,
+      .simd = ISA_EXT_SIMD_LASX,
+  },
 };
 
 struct loongarch_cache
@@ -82,6 +88,12 @@ loongarch_cpu_cache[N_TUNE_TYPES] = {
       .l2d_size = 0,
       .simultaneous_prefetches = 4,
   },
+  [CPU_LA664] = {
+      .l1d_line_size = 64,
+      .l1d_size = 64,
+      .l2d_size = 256,
+      .simultaneous_prefetches = 4,
+  },
 };
 
 /* RTX costs */
@@ -122,6 +134,9 @@ loongarch_cpu_rtx_cost_data[N_TUNE_TYPES] = {
   [CPU_LA264] = {
       DEFAULT_COSTS
   },
+  [CPU_LA664] = {
+      DEFAULT_COSTS
+  },
 };
 
 /* RTX costs to use when optimizing for size.  */
@@ -147,6 +162,7 @@ loongarch_cpu_issue_rate[N_TUNE_TYPES] = {
   [CPU_LA464]	      = 4,
   [CPU_LA364]	      = 3,
   [CPU_LA264]	      = 2,
+  [CPU_LA664]	      = 6,
 };
 
 int
@@ -156,6 +172,7 @@ loongarch_cpu_multipass_dfa_lookahead[N_TUNE_TYPES] = {
   [CPU_LA464]	      = 4,
   [CPU_LA364]	      = 4,
   [CPU_LA264]	      = 4,
+  [CPU_LA664]	      = 4,
 };
 
 /* Wiring string definitions from loongarch-str.h to global arrays
diff --git a/gcc/config/loongarch/loongarch-def.h b/gcc/config/loongarch/loongarch-def.h
index 93ff802ee..45d9ac16c 100644
--- a/gcc/config/loongarch/loongarch-def.h
+++ b/gcc/config/loongarch/loongarch-def.h
@@ -141,9 +141,10 @@ struct loongarch_target
 #define CPU_LA464	  3
 #define CPU_LA364	  4
 #define CPU_LA264	  5
-#define N_ARCH_TYPES	  6
-#define N_TUNE_TYPES	  6
-#define CPU_NONE          7
+#define CPU_LA664	  6
+#define N_ARCH_TYPES	  7
+#define N_TUNE_TYPES	  7
+#define CPU_NONE          8
 
 /* parallel tables */
 extern const char* loongarch_cpu_strings[];
diff --git a/gcc/config/loongarch/loongarch-opts.c b/gcc/config/loongarch/loongarch-opts.c
index ed95ca788..cf11f67d1 100644
--- a/gcc/config/loongarch/loongarch-opts.c
+++ b/gcc/config/loongarch/loongarch-opts.c
@@ -66,9 +66,7 @@ static struct obstack msg_obstack;
 static const char* abi_str (struct loongarch_abi abi);
 static const char* isa_str (const struct loongarch_isa *isa, char separator);
 static const char* arch_str (const struct loongarch_target *target);
-static const char* multilib_enabled_abi_list ();
-
-/* Misc */
+static const char* multilib_enabled_abi_list (); /* Misc */
 static struct loongarch_abi isa_default_abi (const struct loongarch_isa *isa);
 static int isa_base_compat_p (const struct loongarch_isa *set1,
 			      const struct loongarch_isa *set2);
@@ -78,7 +76,7 @@ static int abi_compat_p (const struct loongarch_isa *isa,
 			 struct loongarch_abi abi);
 static int abi_default_cpu_arch (struct loongarch_abi abi, struct loongarch_isa *isa);
 
-/* Checking configure-time defaults.  */
+/* Mandatory configure-time defaults.  */
 #ifndef DEFAULT_ABI_BASE
 #error missing definition of DEFAULT_ABI_BASE in ${tm_defines}.
 #endif
@@ -91,14 +89,29 @@ static int abi_default_cpu_arch (struct loongarch_abi abi, struct loongarch_isa
 #error missing definition of DEFAULT_CPU_ARCH in ${tm_defines}.
 #endif
 
-#ifndef DEFAULT_ISA_EXT_FPU
-#error missing definition of DEFAULT_ISA_EXT_FPU in ${tm_defines}.
+/* Optional configure-time defaults.  */
+#ifdef DEFAULT_CPU_TUNE
+static int with_default_tune = 1;
+#else
+#define DEFAULT_CPU_TUNE -1
+static int with_default_tune = 0;
 #endif
 
-#ifndef DEFAULT_ISA_EXT_SIMD
-#define DEFAULT_ISA_EXT_SIMD ISA_EXT_NONE
+#ifdef DEFAULT_ISA_EXT_FPU
+static int with_default_fpu = 1;
+#else
+#define DEFAULT_ISA_EXT_FPU -1
+static int with_default_fpu = 0;
 #endif
 
+#ifdef DEFAULT_ISA_EXT_SIMD
+static int with_default_simd = 1;
+#else
+#define DEFAULT_ISA_EXT_SIMD -1
+static int with_default_simd = 0;
+#endif
+
+
 /* Initialize loongarch_target from separate option variables.  */
 
 void
@@ -218,11 +231,11 @@ loongarch_config_target (struct loongarch_target *target,
   /* 2.  Target CPU */
   t.cpu_arch = constrained.arch ? target->cpu_arch : DEFAULT_CPU_ARCH;
 
-  /* If cpu_tune is not set using neither --with-tune nor -mtune,
+  /* If cpu_tune is not set using neither -mtune nor --with-tune,
      the current cpu_arch is used as its default. */
   t.cpu_tune = constrained.tune ? target->cpu_tune
     : (constrained.arch ? target->cpu_arch :
-       (DEFAULT_CPU_TUNE == CPU_NONE ? DEFAULT_CPU_ARCH : DEFAULT_CPU_TUNE));
+       (with_default_tune ? DEFAULT_CPU_TUNE : DEFAULT_CPU_ARCH));
 
 
   /* Handle -march/tune=native */
@@ -265,10 +278,12 @@ config_target_isa:
   /* "-march=native" overrides the default FPU type.  */
 
   t.isa.fpu = constrained.fpu ? target->isa.fpu :
-    (constrained.arch ? t.isa.fpu : DEFAULT_ISA_EXT_FPU);
+    (constrained.arch ? t.isa.fpu :
+    (with_default_fpu ? DEFAULT_ISA_EXT_FPU : t.isa.fpu));
 
   t.isa.simd = constrained.simd ? target->isa.simd :
-    (constrained.arch ? t.isa.simd : DEFAULT_ISA_EXT_SIMD);
+    (constrained.arch ? t.isa.simd :
+    (with_default_simd ? DEFAULT_ISA_EXT_SIMD : t.isa.simd));
 
   /* apply -m[no-]lsx and -m[no-]lasx flags */
   if (flags)
diff --git a/gcc/config/loongarch/loongarch-opts.h b/gcc/config/loongarch/loongarch-opts.h
index c96c8a6ed..33eb8b2da 100644
--- a/gcc/config/loongarch/loongarch-opts.h
+++ b/gcc/config/loongarch/loongarch-opts.h
@@ -89,6 +89,7 @@ loongarch_update_gcc_opt_status (struct loongarch_target *target,
 #define TARGET_uARCH_LA464	  (la_target.cpu_tune == CPU_LA464)
 #define TARGET_uARCH_LA364	  (la_target.cpu_tune == CPU_LA364)
 #define TARGET_uARCH_LA264	  (la_target.cpu_tune == CPU_LA264)
+#define TARGET_uARCH_LA664	  (la_target.cpu_tune == CPU_LA664)
 
 /* Note: optimize_size may vary across functions,
    while -m[no]-memcpy imposes a global constraint.  */
diff --git a/gcc/config/loongarch/loongarch-protos.h b/gcc/config/loongarch/loongarch-protos.h
index aaa679fc8..2fb1d1c30 100644
--- a/gcc/config/loongarch/loongarch-protos.h
+++ b/gcc/config/loongarch/loongarch-protos.h
@@ -115,7 +115,6 @@ extern bool loongarch_const_vector_same_int_p (rtx, machine_mode, HOST_WIDE_INT,
 extern bool loongarch_const_vector_shuffle_set_p (rtx, machine_mode);
 extern bool loongarch_const_vector_bitimm_set_p (rtx, machine_mode);
 extern bool loongarch_const_vector_bitimm_clr_p (rtx, machine_mode);
-extern rtx loongarch_lsx_vec_parallel_const_half (machine_mode, bool);
 extern rtx loongarch_gen_const_int_vector (machine_mode, HOST_WIDE_INT);
 extern enum reg_class loongarch_secondary_reload_class (enum reg_class,
 							machine_mode,
@@ -163,8 +162,10 @@ union loongarch_gen_fn_ptrs
 extern void loongarch_expand_atomic_qihi (union loongarch_gen_fn_ptrs,
 					  rtx, rtx, rtx, rtx, rtx);
 
+extern void loongarch_expand_vector_group_init (rtx, rtx);
 extern void loongarch_expand_vector_init (rtx, rtx);
 extern void loongarch_expand_vec_unpack (rtx op[2], bool, bool);
+extern void loongarch_expand_fp_vec_unpack (rtx op[2], bool);
 extern void loongarch_expand_vec_perm (rtx, rtx, rtx, rtx);
 extern void loongarch_expand_vec_perm_1 (rtx[]);
 extern void loongarch_expand_vector_extract (rtx, rtx, int);
@@ -205,6 +206,7 @@ extern tree loongarch_builtin_vectorized_function (unsigned int, tree, tree);
 extern rtx loongarch_gen_const_int_vector_shuffle (machine_mode, int);
 extern tree loongarch_build_builtin_va_list (void);
 extern rtx loongarch_build_signbit_mask (machine_mode, bool, bool);
-extern void loongarch_emit_swrsqrtsf (rtx, rtx, machine_mode);
+extern void loongarch_emit_swrsqrtsf (rtx, rtx, machine_mode, bool);
+extern void loongarch_emit_swdivsf (rtx, rtx, rtx, machine_mode);
 extern rtx loongarch_prefetch_cookie (rtx, rtx);
 #endif /* ! GCC_LARCH_PROTOS_H */
diff --git a/gcc/config/loongarch/loongarch-str.h b/gcc/config/loongarch/loongarch-str.h
index f49ff5e7e..aca3d667b 100644
--- a/gcc/config/loongarch/loongarch-str.h
+++ b/gcc/config/loongarch/loongarch-str.h
@@ -32,6 +32,7 @@ along with GCC; see the file COPYING3.  If not see
 #define STR_CPU_LA464 "la464"
 #define STR_CPU_LA364 "la364"
 #define STR_CPU_LA264 "la264"
+#define STR_CPU_LA664 "la664"
 
 #define STR_ISA_BASE_LA64V100 "la64"
 
diff --git a/gcc/config/loongarch/loongarch.c b/gcc/config/loongarch/loongarch.c
index 5bcd45027..2fdfe4a4a 100644
--- a/gcc/config/loongarch/loongarch.c
+++ b/gcc/config/loongarch/loongarch.c
@@ -1193,7 +1193,9 @@ static void
 loongarch_emit_stack_tie (void)
 {
   emit_insn (PMODE_INSN (gen_stack_tie,
-			 (stack_pointer_rtx, hard_frame_pointer_rtx)));
+			 (stack_pointer_rtx, frame_pointer_needed
+					     ? hard_frame_pointer_rtx
+					     : stack_pointer_rtx)));
 }
 
 #define PROBE_INTERVAL (1 << STACK_CHECK_PROBE_INTERVAL_EXP)
@@ -1565,6 +1567,7 @@ loongarch_expand_epilogue (bool sibcall_p)
 
      Start off by assuming that no registers need to be restored.  */
   struct loongarch_frame_info *frame = &cfun->machine->frame;
+  unsigned mask = frame->mask;
   HOST_WIDE_INT step1 = frame->total_size;
   HOST_WIDE_INT step2 = 0;
   rtx ra = gen_rtx_REG (Pmode, RETURN_ADDR_REGNUM);
@@ -1702,6 +1705,8 @@ loongarch_expand_epilogue (bool sibcall_p)
   loongarch_for_each_saved_reg (frame->total_size - step2,
 				loongarch_restore_reg);
 
+  cfun->machine->frame.mask = mask;
+
   if (need_barrier_p)
     loongarch_emit_stack_tie ();
 
@@ -5475,6 +5480,8 @@ loongarch_print_operand_punct_valid_p (unsigned char code)
 /* Return true if a FENCE should be emitted to before a memory access to
    implement the release portion of memory model MODEL.  */
 
+#pragma GCC diagnostic push
+#pragma GCC diagnostic ignored "-Wimplicit-fallthrough"
 static bool
 loongarch_memmodel_needs_rel_acq_fence (enum memmodel model)
 {
@@ -5483,13 +5490,15 @@ loongarch_memmodel_needs_rel_acq_fence (enum memmodel model)
       case MEMMODEL_ACQ_REL:
       case MEMMODEL_SEQ_CST:
       case MEMMODEL_SYNC_SEQ_CST:
-      case MEMMODEL_RELEASE:
       case MEMMODEL_SYNC_RELEASE:
-      case MEMMODEL_ACQUIRE:
-      case MEMMODEL_CONSUME:
       case MEMMODEL_SYNC_ACQUIRE:
 	return true;
 
+      case MEMMODEL_RELEASE:
+      case MEMMODEL_ACQUIRE:
+      case MEMMODEL_CONSUME:
+	if (!TARGET_uARCH_LA664)
+	  return true;
       case MEMMODEL_RELAXED:
 	return false;
 
@@ -5497,6 +5506,7 @@ loongarch_memmodel_needs_rel_acq_fence (enum memmodel model)
 	gcc_unreachable ();
     }
 }
+#pragma GCC diagnostic pop
 
 /* Return true if a FENCE should be emitted to before a memory access to
    implement the release portion of memory model MODEL.  */
@@ -5747,7 +5757,25 @@ loongarch_print_operand (FILE *file, rtx op, int letter)
 
     case 'G':
       if (loongarch_memmodel_needs_release_fence ((enum memmodel) INTVAL (op)))
-	fputs ("dbar\t0", file);
+	fputs ("dbar\t0x11", file);
+      break;
+
+    case 'J':
+      if (TARGET_uARCH_LA664)
+	{
+	  enum memmodel model = memmodel_from_int (INTVAL (op));
+	  if (is_mm_release (model))
+	    fputs ("dbar\t0x12", file);
+	}
+      break;
+
+    case 'K':
+      if (TARGET_uARCH_LA664)
+	{
+	  enum memmodel model = memmodel_from_int (INTVAL (op));
+	  if (is_mm_acquire (model))
+	    fputs ("dbar\t0x18", file);
+	}
       break;
 
     case 'i':
@@ -6410,6 +6438,18 @@ loongarch_register_move_cost (machine_mode mode, reg_class_t from,
   return 0;
 }
 
+/* Return a register priority for hard reg REGNO.  */
+
+static int
+loongarch_register_priority (int regno)
+{
+  /* Lower the priority of registers t3 through t8. */
+  if (IN_RANGE (regno, GP_REG_FIRST + 15, GP_REG_FIRST + 20))
+    return 1;
+
+  return 2;
+}
+
 /* Implement TARGET_MEMORY_MOVE_COST.  */
 
 static int
@@ -7013,6 +7053,12 @@ loongarch_cpu_option_override (struct loongarch_target *target,
   maybe_set_param_value (PARAM_L2_CACHE_SIZE,
     loongarch_cpu_cache[target->cpu_tune].l2d_size,
     opts->x_param_values, opts_set->x_param_values);
+
+  /* Use the 'model' -fsched-pressure algorithm by default.  */
+  maybe_set_param_value (PARAM_SCHED_PRESSURE_ALGORITHM,
+			 SCHED_PRESSURE_MODEL,
+			 opts->x_param_values,
+			 global_options_set.x_param_values);
 }
 
 static void
@@ -7121,6 +7167,71 @@ loongarch_option_override_internal (struct gcc_options *opts,
     }
   if (!ISA_HAS_LASX)
     loongarch_stack_realign = 0;
+
+  /* -mrecip options.  */
+  static struct
+    {
+      const char *string;           /* option name */
+      unsigned int mask;            /* mask bits to set */
+    }
+  const recip_options[] =
+    {
+      { "all",       RECIP_MASK_ALL },
+      { "none",      RECIP_MASK_NONE },
+      { "div",       RECIP_MASK_DIV },
+      { "sqrt",      RECIP_MASK_SQRT },
+      { "rsqrt",     RECIP_MASK_RSQRT },
+      { "vec-div",   RECIP_MASK_VEC_DIV },
+      { "vec-sqrt",  RECIP_MASK_VEC_SQRT },
+      { "vec-rsqrt", RECIP_MASK_VEC_RSQRT },
+    };
+
+  if (loongarch_recip_name)
+  {
+    char *p = ASTRDUP (loongarch_recip_name);
+    char *q;
+    unsigned int mask, i;
+    bool invert;
+
+    while ((q = strtok (p, ",")) != NULL)
+     {
+       p = NULL;
+       if (*q == '!')
+         {
+           invert = true;
+           q++;
+         }
+       else
+         invert = false;
+
+       if (!strcmp (q, "default"))
+         mask = RECIP_MASK_ALL;
+       else
+         {
+           for (i = 0; i < ARRAY_SIZE (recip_options); i++)
+             if (!strcmp (q, recip_options[i].string))
+               {
+                 mask = recip_options[i].mask;
+                 break;
+               }
+
+           if (i == ARRAY_SIZE (recip_options))
+             {
+               error ("unknown option for -mrecip=%s", q);
+               invert = false;
+               mask = RECIP_MASK_NONE;
+             }
+         }
+
+       if (invert)
+         recip_mask &= ~mask;
+       else
+         recip_mask |= mask;
+     }
+  }
+  if (loongarch_recip)
+    recip_mask |= RECIP_MASK_ALL;
+
 }
 
 
@@ -9260,6 +9371,7 @@ loongarch_cpu_sched_reassociation_width (struct loongarch_target *target,
     {
     case CPU_LOONGARCH64:
     case CPU_LA464:
+    case CPU_LA664:
       /* Vector part.  */
       if (LSX_SUPPORTED_MODE_P (mode) || LASX_SUPPORTED_MODE_P (mode))
         {
@@ -9434,6 +9546,21 @@ loongarch_expand_vector_reduc (rtx (*fn) (rtx, rtx, rtx), rtx dest, rtx in)
     }
 }
 
+/* Expand a float vector unpack operation.  */
+
+void
+loongarch_expand_fp_vec_unpack(rtx operands[2], bool high_p)
+{
+  rtx tmp = gen_reg_rtx (V8SFmode);
+
+  /* { 0 1 2 3 4 5 6 7 } -> { 0 1 4 5 2 3 6 7 } */
+  emit_insn (gen_lasx_xvpermi_d_v8sf (tmp, operands[1], GEN_INT (0xd8)));
+  if (high_p)
+    emit_insn (gen_lasx_xvfcvth_d_s(operands[0], tmp));
+  else
+    emit_insn (gen_lasx_xvfcvtl_d_s(operands[0], tmp));
+}
+
 /* Expand an integral vector unpack operation.  */
 
 void
@@ -9548,25 +9675,6 @@ loongarch_expand_vec_unpack (rtx operands[2], bool unsigned_p, bool high_p)
   gcc_unreachable ();
 }
 
-/* Construct and return PARALLEL RTX with CONST_INTs for HIGH (high_p == TRUE)
-   or LOW (high_p == FALSE) half of a vector for mode MODE.  */
-
-rtx
-loongarch_lsx_vec_parallel_const_half (machine_mode mode, bool high_p)
-{
-  int nunits = GET_MODE_NUNITS (mode);
-  rtvec v = rtvec_alloc (nunits / 2);
-  int base;
-  int i;
-
-  base = high_p ? nunits / 2 : 0;
-
-  for (i = 0; i < nunits / 2; i++)
-    RTVEC_ELT (v, i) = GEN_INT (base + i);
-
-  return gen_rtx_PARALLEL (VOIDmode, v);
-}
-
 /* A subroutine of loongarch_expand_vec_init, match constant vector elements.  */
 
 static inline bool
@@ -9596,6 +9704,14 @@ loongarch_gen_const_int_vector_shuffle (machine_mode mode, int val)
 
 /* Expand a vector initialization.  */
 
+void
+loongarch_expand_vector_group_init (rtx target, rtx vals)
+{
+  rtx ops[2] = { XVECEXP (vals, 0, 0), XVECEXP (vals, 0, 1) };
+  emit_insn (gen_rtx_SET (target, gen_rtx_VEC_CONCAT (E_V32QImode, ops[0],
+            ops[1])));
+}
+
 void
 loongarch_expand_vector_init (rtx target, rtx vals)
 {
@@ -10494,67 +10610,117 @@ loongarch_build_signbit_mask (machine_mode mode, bool vect, bool invert)
   return force_reg (vec_mode, v);
 }
 
-/* Emit code for rsqrt calculation.  */
+/* Use rsqrte instruction and Newton-Rhapson to compute the approximation of
+   a single precision floating point [reciprocal] square root.  */
 
-void loongarch_emit_swrsqrtsf (rtx res, rtx a, machine_mode mode)
+void loongarch_emit_swrsqrtsf (rtx res, rtx a, machine_mode mode, bool recip)
 {
-  rtx x0, e0, e1, e2, e3, e4, e5, e6, e7, mhalf, mmagic, monehalf, mone;
-  machine_mode imode = SImode;
+  rtx x0, e0, e1, e2, mhalf, monehalf;
   REAL_VALUE_TYPE r;
+  machine_mode imode;
+  int unspec;
 
   x0 = gen_reg_rtx (mode);
   e0 = gen_reg_rtx (mode);
   e1 = gen_reg_rtx (mode);
   e2 = gen_reg_rtx (mode);
-  e3 = gen_reg_rtx (mode);
-  e4 = gen_reg_rtx (mode);
-  e5 = gen_reg_rtx (mode);
-  e6 = gen_reg_rtx (mode);
-  e7 = gen_reg_rtx (mode);
 
   real_arithmetic (&r, ABS_EXPR, &dconsthalf, NULL);
   mhalf = const_double_from_real_value (r, SFmode);
 
   real_arithmetic (&r, PLUS_EXPR, &dconsthalf, &dconst1);
   monehalf = const_double_from_real_value (r, SFmode);
-
-  mone = GEN_INT (0x1);
-  mmagic = GEN_INT (0x5f3759df);
+  unspec = UNSPEC_RSQRTE;
 
   if (VECTOR_MODE_P (mode))
     {
-      imode = LASX_SUPPORTED_MODE_P(mode) ? V8SImode : V4SImode;
       mhalf = loongarch_build_const_vector (mode, true, mhalf);
-      mmagic = loongarch_build_const_vector (imode, true, mmagic);
       monehalf = loongarch_build_const_vector (mode, true, monehalf);
-      mone = loongarch_build_const_vector (imode, true, mone);
+      if (GET_MODE_SIZE (mode) == 32)
+	imode = mode == V4DFmode ? V4DImode : V8SImode;
+      if (GET_MODE_SIZE (mode) == 16)
+	imode = mode == V2DFmode ? V2DImode : V4SImode;
     }
 
-  rtx x1 = gen_reg_rtx (imode);
-  rtx x2 = gen_reg_rtx (imode);
+  /* rsqrt(a) =  rsqrte(a) * (1.5 - 0.5 * a * rsqrte(a) * rsqrte(a))
+     sqrt(a)  =  a * rsqrte(a) * (1.5 - 0.5 * a * rsqrte(a) * rsqrte(a))*/
 
-  /* x2 = rsqrt(a) estimate */
-  emit_insn (gen_rtx_SET (x1, gen_rtx_ASHIFTRT (imode, gen_lowpart (imode, a), mone)));
-  mhalf = force_reg (mode, mhalf);
-  emit_insn (gen_rtx_SET (x0, gen_rtx_MULT (mode, mhalf, a)));
-  mmagic = force_reg (imode, mmagic);
-  emit_insn (gen_rtx_SET (x2, gen_rtx_MINUS (imode, mmagic, x1)));
+  a = force_reg (mode, a);
+
+  /* x0 = rsqrt(a) estimate */
+  emit_insn (gen_rtx_SET (x0, gen_rtx_UNSPEC (mode, gen_rtvec (1, a),
+                                              unspec)));
+
+  /* If (a == 0.0) Filter out infinity to prevent NaN for sqrt(0.0).  */
+  if (!recip)
+    {
+      rtx zero = force_reg (mode, CONST0_RTX(mode));
 
-  /* rsqrt(a) =  rsqrtss(a) * (1.5 - 0.5 * a * rsqrtss(a) * rsqrtss(a)) */
-  emit_insn (gen_rtx_SET (e0, gen_rtx_MULT (mode, gen_lowpart (mode, x2), gen_lowpart (mode, x2))));
+      if (VECTOR_MODE_P (mode))
+	{
+	  rtx mask = gen_reg_rtx (imode);
+	  emit_insn (gen_rtx_SET (mask, gen_rtx_NE (imode, a, zero)));
+	  emit_insn (gen_rtx_SET (x0, gen_rtx_AND (mode, x0, gen_lowpart(mode, mask))));
+        }
+      else
+	{
+	  rtx target = emit_conditional_move (x0, GT, a, zero, mode,
+                    x0, zero, mode, 0);
+          if (target != x0)
+            emit_move_insn (x0, target);
+        }
+    }
+
+  /* e0 = x0 * a */
+  emit_insn (gen_rtx_SET (e0, gen_rtx_MULT (mode, x0, a)));
+  /* e1 = e0 * x0 */
+  emit_insn (gen_rtx_SET (e1, gen_rtx_MULT (mode, e0, x0)));
+
+  /* e2 = 1.5 - e1 * 0.5 */
+  mhalf = force_reg (mode, mhalf);
   monehalf = force_reg (mode, monehalf);
-  emit_insn (gen_rtx_SET (e1, gen_rtx_FMA (mode, gen_rtx_NEG(mode, e0), x0, monehalf)));
-  emit_insn (gen_rtx_SET (e2, gen_rtx_MULT (mode, gen_lowpart (mode, x2), e1)));
+  emit_insn (gen_rtx_SET (e2, gen_rtx_FMA (mode, gen_rtx_NEG(mode, e1), mhalf, monehalf)));
+
+  if (recip)
+    /* res = e2 * x0 */
+    emit_insn (gen_rtx_SET (res, gen_rtx_MULT (mode, x0, e2)));
+  else
+    /* res = e2 * e0 */
+    emit_insn (gen_rtx_SET (res, gen_rtx_MULT (mode, e2, e0)));
+}
+
+/* Use recipe instruction and Newton-Rhapson to compute the approximation of
+   a single precision floating point divide.  */
+
+void loongarch_emit_swdivsf (rtx res, rtx a, rtx b, machine_mode mode)
+{
+  rtx x0, x1, e0, mtwo;
+  REAL_VALUE_TYPE r;
+  x0 = gen_reg_rtx (mode);
+  e0 = gen_reg_rtx (mode);
+  x1 = gen_reg_rtx (mode);
+
+  real_arithmetic (&r, ABS_EXPR, &dconst2, NULL);
+  mtwo = const_double_from_real_value (r, SFmode);
+
+  if (VECTOR_MODE_P (mode))
+    mtwo = loongarch_build_const_vector (mode, true, mtwo);
+
+  mtwo = force_reg (mode, mtwo);
+
+  /* a / b = a * recipe(b) * (2.0 - b * recipe(b)) */
 
-  /* 2nd iteration */
-  emit_insn (gen_rtx_SET (e3, gen_rtx_MULT (mode, gen_lowpart (mode, e2), gen_lowpart (mode, e2))));
-  emit_insn (gen_rtx_SET (e4, gen_rtx_FMA (mode, gen_rtx_NEG(mode, e3), x0, monehalf)));
-  emit_insn (gen_rtx_SET (e5, gen_rtx_MULT (mode, gen_lowpart (mode, e2), e4)));
+  /* x0 = 1./b estimate */
+  emit_insn (gen_rtx_SET (x0, gen_rtx_UNSPEC (mode, gen_rtvec (1, b),
+                                              UNSPEC_RECIPE)));
+  /* 2.0 - b * x0; */
+  emit_insn (gen_rtx_SET (e0, gen_rtx_FMA (mode,gen_rtx_NEG(mode, b), x0, mtwo)));
 
-  /* 3rd iteration */
-  emit_insn (gen_rtx_SET (e6, gen_rtx_MULT (mode, gen_lowpart (mode, e5), gen_lowpart (mode, e5))));
-  emit_insn (gen_rtx_SET (e7, gen_rtx_FMA (mode, gen_rtx_NEG(mode, e6), x0, monehalf)));
-  emit_insn (gen_rtx_SET (res, gen_rtx_MULT (mode, gen_lowpart (mode, e5), e7)));
+  /* x1 = a * x0 */
+  emit_insn (gen_rtx_SET (x1, gen_rtx_MULT (mode, a, x0)));
+
+  /* res = e0 * x1 */
+  emit_insn (gen_rtx_SET (res, gen_rtx_MULT (mode, e0, x1)));
 }
 
 /* LoongArch only implements preld hint=0 (prefetch for load) and hint=8
@@ -10577,7 +10743,6 @@ loongarch_prefetch_cookie (rtx write, rtx locality)
   gcc_unreachable ();
 }
 
-
 
 /* Initialize the GCC target structure.  */
 #undef TARGET_ASM_ALIGNED_HI_OP
@@ -10625,6 +10790,8 @@ loongarch_prefetch_cookie (rtx write, rtx locality)
 #undef TARGET_REGISTER_MOVE_COST
 #define TARGET_REGISTER_MOVE_COST loongarch_register_move_cost
 #undef TARGET_MEMORY_MOVE_COST
+#undef TARGET_REGISTER_PRIORITY
+#define TARGET_REGISTER_PRIORITY loongarch_register_priority
 #define TARGET_MEMORY_MOVE_COST loongarch_memory_move_cost
 #undef TARGET_RTX_COSTS
 #define TARGET_RTX_COSTS loongarch_rtx_costs
diff --git a/gcc/config/loongarch/loongarch.h b/gcc/config/loongarch/loongarch.h
index 15634cfa4..b32c2604b 100644
--- a/gcc/config/loongarch/loongarch.h
+++ b/gcc/config/loongarch/loongarch.h
@@ -735,6 +735,24 @@ enum reg_class
    && (GET_MODE_CLASS (MODE) == MODE_VECTOR_INT		\
        || GET_MODE_CLASS (MODE) == MODE_VECTOR_FLOAT))
 
+#define RECIP_MASK_NONE         0x00
+#define RECIP_MASK_DIV          0x01
+#define RECIP_MASK_SQRT         0x02
+#define RECIP_MASK_RSQRT        0x04
+#define RECIP_MASK_VEC_DIV      0x08
+#define RECIP_MASK_VEC_SQRT     0x10
+#define RECIP_MASK_VEC_RSQRT    0x20
+#define RECIP_MASK_ALL (RECIP_MASK_DIV | RECIP_MASK_SQRT \
+                        | RECIP_MASK_RSQRT | RECIP_MASK_VEC_SQRT \
+			| RECIP_MASK_VEC_DIV | RECIP_MASK_VEC_RSQRT)
+
+#define TARGET_RECIP_DIV	((recip_mask & RECIP_MASK_DIV) != 0 || TARGET_uARCH_LA664)
+#define TARGET_RECIP_SQRT	((recip_mask & RECIP_MASK_SQRT) != 0 || TARGET_uARCH_LA664)
+#define TARGET_RECIP_RSQRT	((recip_mask & RECIP_MASK_RSQRT) != 0 || TARGET_uARCH_LA664)
+#define TARGET_RECIP_VEC_DIV	((recip_mask & RECIP_MASK_VEC_DIV) != 0 || TARGET_uARCH_LA664)
+#define TARGET_RECIP_VEC_SQRT	((recip_mask & RECIP_MASK_VEC_SQRT) != 0 || TARGET_uARCH_LA664)
+#define TARGET_RECIP_VEC_RSQRT	((recip_mask & RECIP_MASK_VEC_RSQRT) != 0 || TARGET_uARCH_LA664)
+
 /* 1 if N is a possible register number for function argument passing.
    We have no FP argument registers when soft-float.  */
 
@@ -1197,7 +1215,7 @@ typedef struct {
 
 #define MOVE_RATIO(speed) \
   (HAVE_movmemsi \
-   ? LARCH_MAX_MOVE_BYTES_PER_LOOP_ITER / UNITS_PER_WORD \
+   ? LARCH_MAX_MOVE_BYTES_PER_LOOP_ITER / UNITS_PER_WORD + 1 \
    : CLEAR_RATIO (speed) / 2)
 
 /* For CLEAR_RATIO, when optimizing for size, give a better estimate
diff --git a/gcc/config/loongarch/loongarch.md b/gcc/config/loongarch/loongarch.md
index cddf76141..4e02660d3 100644
--- a/gcc/config/loongarch/loongarch.md
+++ b/gcc/config/loongarch/loongarch.md
@@ -66,6 +66,10 @@
 
   ;; RSQRT
   UNSPEC_RSQRT
+  UNSPEC_RSQRTE
+
+  ;; RECIP
+  UNSPEC_RECIPE
 ])
 
 (define_c_enum "unspecv" [
@@ -220,6 +224,7 @@
 ;; fcvt		floating point convert
 ;; fsqrt	floating point square root
 ;; frsqrt       floating point reciprocal square root
+;; frsqrte      float point reciprocal square root approximate
 ;; multi	multiword sequence (or user asm statements)
 ;; atomic	atomic memory update instruction
 ;; syncloop	memory atomic operation implemented as a sync loop
@@ -230,7 +235,7 @@
    prefetch,prefetchx,condmove,mgtf,mftg,const,arith,logical,
    shift,slt,signext,clz,trap,imul,idiv,move,
    fmove,fadd,fmul,fmadd,fdiv,frdiv,fabs,fneg,fcmp,fcopysign,fcvt,fsqrt,
-   frsqrt,accext,accmod,multi,atomic,syncloop,nop,ghost,
+   frsqrt,frsqrte,accext,accmod,multi,atomic,syncloop,nop,ghost,
    simd_div,simd_fclass,simd_flog2,simd_fadd,simd_fcvt,simd_fmul,simd_fmadd,
    simd_fdiv,simd_bitins,simd_bitmov,simd_insert,simd_sld,simd_mul,simd_fcmp,
    simd_fexp2,simd_int_arith,simd_bit,simd_shift,simd_splat,simd_fill,
@@ -694,15 +699,6 @@
   [(set_attr "type" "imul")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "mulsidi3_64bit"
-  [(set (match_operand:DI 0 "register_operand" "=r")
-	(mult:DI (sign_extend:DI (match_operand:SI 1 "register_operand" "r"))
-		 (sign_extend:DI (match_operand:SI 2 "register_operand" "r"))))]
-  "TARGET_64BIT"
-  "mul.d\t%0,%1,%2"
-  [(set_attr "type" "imul")
-   (set_attr "mode" "DI")])
-
 (define_insn "*mulsi3_extended"
   [(set (match_operand:DI 0 "register_operand" "=r")
 	(sign_extend:DI
@@ -753,21 +749,33 @@
    (set_attr "mode" "DI")])
 
 (define_expand "<u>mulsidi3"
-  [(set (match_operand:DI 0 "register_operand" "=r")
+  [(set (match_operand:DI 0 "register_operand")
 	(mult:DI (any_extend:DI
-		   (match_operand:SI 1 "register_operand" " r"))
+		   (match_operand:SI 1 "register_operand"))
 		 (any_extend:DI
-		   (match_operand:SI 2 "register_operand" " r"))))]
-  "!TARGET_64BIT"
+		   (match_operand:SI 2 "register_operand"))))]
+  ""
 {
-  rtx temp = gen_reg_rtx (SImode);
-  emit_insn (gen_mulsi3 (temp, operands[1], operands[2]));
-  emit_insn (gen_<u>mulsi3_highpart (loongarch_subword (operands[0], true),
+  if (!TARGET_64BIT)
+    {
+      rtx temp = gen_reg_rtx (SImode);
+      emit_insn (gen_mulsi3 (temp, operands[1], operands[2]));
+      emit_insn (gen_<u>mulsi3_highpart (loongarch_subword (operands[0], true),
 				     operands[1], operands[2]));
-  emit_insn (gen_movsi (loongarch_subword (operands[0], false), temp));
-  DONE;
+      emit_insn (gen_movsi (loongarch_subword (operands[0], false), temp));
+      DONE;
+    }
 })
 
+(define_insn "<u>mulsidi3_64bit"
+  [(set (match_operand:DI 0 "register_operand" "=r")
+	(mult:DI (any_extend:DI (match_operand:SI 1 "register_operand" "r"))
+		 (any_extend:DI (match_operand:SI 2 "register_operand" "r"))))]
+  "TARGET_64BIT"
+  "mulw.d.w<u>\t%0,%1,%2"
+  [(set_attr "type" "imul")
+   (set_attr "mode" "DI")])
+
 (define_insn "<u>mulsi3_highpart"
   [(set (match_operand:SI 0 "register_operand" "=r")
 	(truncate:SI
@@ -777,7 +785,7 @@
 		     (any_extend:DI
 		       (match_operand:SI 2 "register_operand" " r")))
 	    (const_int 32))))]
-  "!TARGET_64BIT"
+  ""
   "mulh.w<u>\t%0,%1,%2"
   [(set_attr "type" "imul")
    (set_attr "mode" "SI")])
@@ -823,9 +831,21 @@
 ;; Float division and modulus.
 (define_expand "div<mode>3"
   [(set (match_operand:ANYF 0 "register_operand")
-	(div:ANYF (match_operand:ANYF 1 "reg_or_1_operand")
+	(div:ANYF (match_operand:ANYF 1 "register_operand")
 		  (match_operand:ANYF 2 "register_operand")))]
-  "")
+  ""
+{
+  if (<MODE>mode == SFmode
+    && TARGET_RECIP_DIV
+    && optimize_insn_for_speed_p ()
+    && flag_finite_math_only && !flag_trapping_math
+    && flag_unsafe_math_optimizations)
+  {
+    loongarch_emit_swdivsf (operands[0], operands[1],
+           operands[2], SFmode);
+    DONE;
+  }
+})
 
 (define_insn "*div<mode>3"
   [(set (match_operand:ANYF 0 "register_operand" "=f")
@@ -849,6 +869,18 @@
    (set_attr "mode" "<UNITMODE>")
    (set_attr "insn_count" "1")])
 
+;; In 3A6000, frecipe calculates the approximate value of the reciprocal operation
+
+(define_insn "recipe<mode>2"
+  [(set (match_operand:ANYF 0 "register_operand" "=f")
+    (unspec:ANYF [(match_operand:ANYF 1 "register_operand" "f")]
+              UNSPEC_RECIPE))]
+  "TARGET_HARD_FLOAT && flag_unsafe_math_optimizations"
+  "frecipe.<fmt>\t%0,%1"
+  [(set_attr "type" "frsqrte")
+   (set_attr "mode" "<UNITMODE>")
+   (set_attr "insn_count" "1")])
+
 ;; Integer division and modulus.
 (define_expand "<optab><mode>3"
   [(set (match_operand:GPR 0 "register_operand")
@@ -1012,7 +1044,7 @@
 ;;
 ;;  ....................
 
-(define_insn "sqrt<mode>2"
+(define_insn "*sqrt<mode>2"
   [(set (match_operand:ANYF 0 "register_operand" "=f")
 	(sqrt:ANYF (match_operand:ANYF 1 "register_operand" "f")))]
   ""
@@ -1021,16 +1053,57 @@
    (set_attr "mode" "<UNITMODE>")
    (set_attr "insn_count" "1")])
 
-(define_expand "rsqrtsf2"
-  [(set (match_operand:SF 0 "register_operand")
-    (unspec:SF [(match_operand:SF 1 "register_operand")]
+(define_expand "sqrt<mode>2"
+  [(set (match_operand:ANYF 0 "register_operand")
+    (sqrt:ANYF (match_operand:ANYF 1 "register_operand")))]
+  ""
+{
+  if (<MODE>mode == SFmode
+      && TARGET_RECIP_SQRT
+      && flag_unsafe_math_optimizations
+      && !optimize_insn_for_size_p ()
+      && flag_finite_math_only && !flag_trapping_math)
+    {
+      loongarch_emit_swrsqrtsf (operands[0], operands[1], SFmode, 0);
+      DONE;
+    }
+})
+
+(define_expand "rsqrt<mode>2"
+  [(set (match_operand:ANYF 0 "register_operand")
+    (unspec:ANYF [(match_operand:ANYF 1 "register_operand")]
            UNSPEC_RSQRT))]
-  "flag_unsafe_math_optimizations && flag_finite_math_only"
+  "TARGET_HARD_FLOAT && flag_unsafe_math_optimizations"
 {
-  loongarch_emit_swrsqrtsf (operands[0], operands[1], SFmode);
-  DONE;
+   if (<MODE>mode == SFmode
+       && TARGET_RECIP_RSQRT
+       && flag_unsafe_math_optimizations
+       && !optimize_insn_for_size_p ()
+       && flag_finite_math_only && !flag_trapping_math)
+     {
+       loongarch_emit_swrsqrtsf (operands[0], operands[1], SFmode, 1);
+       DONE;
+     }
 })
 
+(define_insn "*rsqrt<mode>2"
+  [(set (match_operand:ANYF 0 "register_operand" "=f")
+    (unspec:ANYF [(match_operand:ANYF 1 "register_operand" "f")]
+           UNSPEC_RSQRT))]
+  "TARGET_HARD_FLOAT && flag_unsafe_math_optimizations"
+  "frsqrt.<fmt>\t%0,%1"
+  [(set_attr "type" "frsqrt")
+   (set_attr "mode" "<UNITMODE>")])
+
+(define_insn "rsqrte<mode>"
+  [(set (match_operand:ANYF 0 "register_operand" "=f")
+    (unspec:ANYF [(match_operand:ANYF 1 "register_operand" "f")]
+              UNSPEC_RSQRTE))]
+  "TARGET_HARD_FLOAT && flag_unsafe_math_optimizations"
+  "frsqrte.<fmt>\t%0,%1"
+  [(set_attr "type" "frsqrte")
+   (set_attr "mode" "<UNITMODE>")])
+
 (define_insn "*rsqrt<mode>a"
   [(set (match_operand:ANYF 0 "register_operand" "=f")
 	(div:ANYF (match_operand:ANYF 1 "const_1_operand" "")
diff --git a/gcc/config/loongarch/loongarch.opt b/gcc/config/loongarch/loongarch.opt
index 48b667c82..075a2d6c7 100644
--- a/gcc/config/loongarch/loongarch.opt
+++ b/gcc/config/loongarch/loongarch.opt
@@ -33,6 +33,9 @@ config/loongarch/loongarch-opts.h
 HeaderInclude
 config/loongarch/loongarch-str.h
 
+TargetVariable
+unsigned int recip_mask = 0
+
 ; ISA related options
 ;; Base ISA
 Enum
@@ -42,7 +45,6 @@ Basic ISAs of LoongArch:
 EnumValue
 Enum(isa_base) String(la64) Value(ISA_BASE_LA64V100)
 
-
 ;; ISA extensions / adjustments
 Enum
 Name(isa_ext_fpu) Type(int)
@@ -115,6 +117,9 @@ Enum(cpu_type) String(abi-default) Value(CPU_ABI_DEFAULT)
 EnumValue
 Enum(cpu_type) String(loongarch64) Value(CPU_LOONGARCH64)
 
+EnumValue
+Enum(cpu_type) String(la664) Value(CPU_LA664)
+
 EnumValue
 Enum(cpu_type) String(la464) Value(CPU_LA464)
 
@@ -211,6 +216,14 @@ mmax-inline-memcpy-size=
 Target Joined RejectNegative UInteger Var(loongarch_max_inline_memcpy_size) Init(1024)
 -mmax-inline-memcpy-size=SIZE	Set the max size of memcpy to inline, default is 1024.
 
+mrecip
+Target Report RejectNegative Var(loongarch_recip)
+Generate reciprocals instead of divss and sqrtss.
+
+mrecip=
+Target Report RejectNegative Joined Var(loongarch_recip_name)
+Control generation of reciprocal estimates.
+
 ; The code model option names for -mcmodel.
 Enum
 Name(cmodel) Type(int)
diff --git a/gcc/config/loongarch/lsx.md b/gcc/config/loongarch/lsx.md
index bedfcbdfb..02f5055d2 100644
--- a/gcc/config/loongarch/lsx.md
+++ b/gcc/config/loongarch/lsx.md
@@ -294,6 +294,10 @@
    (V2DI "d")
    (V4SI "s")])
 
+(define_mode_attr flsxfrint
+  [(V2DF "d")
+   (V4SF "s")])
+
 (define_mode_attr ilsxfmt
   [(V2DF "l")
    (V4SF "w")])
@@ -330,6 +334,38 @@
    (V4SI  "uimm5")
    (V2DI  "uimm6")])
 
+
+(define_int_iterator FRINT_S [UNSPEC_LSX_VFRINTRP_S
+			    UNSPEC_LSX_VFRINTRZ_S
+			    UNSPEC_LSX_VFRINT 
+			    UNSPEC_LSX_VFRINTRM_S])
+
+(define_int_iterator FRINT_D [UNSPEC_LSX_VFRINTRP_D
+			    UNSPEC_LSX_VFRINTRZ_D
+			    UNSPEC_LSX_VFRINT 
+			    UNSPEC_LSX_VFRINTRM_D])
+
+(define_int_attr frint_pattern_s
+  [(UNSPEC_LSX_VFRINTRP_S  "ceil")
+   (UNSPEC_LSX_VFRINTRZ_S  "btrunc")
+   (UNSPEC_LSX_VFRINT	   "rint")
+   (UNSPEC_LSX_VFRINTRM_S  "floor")])
+
+(define_int_attr frint_pattern_d
+  [(UNSPEC_LSX_VFRINTRP_D  "ceil")
+   (UNSPEC_LSX_VFRINTRZ_D  "btrunc")
+   (UNSPEC_LSX_VFRINT	   "rint")
+   (UNSPEC_LSX_VFRINTRM_D  "floor")])
+
+(define_int_attr frint_suffix
+  [(UNSPEC_LSX_VFRINTRP_S  "rp")
+   (UNSPEC_LSX_VFRINTRP_D  "rp")
+   (UNSPEC_LSX_VFRINTRZ_S  "rz")
+   (UNSPEC_LSX_VFRINTRZ_D  "rz")
+   (UNSPEC_LSX_VFRINT	   "")
+   (UNSPEC_LSX_VFRINTRM_S  "rm")
+   (UNSPEC_LSX_VFRINTRM_D  "rm")])
+
 (define_expand "vec_init<mode><unitmode>"
   [(match_operand:LSX 0 "register_operand")
    (match_operand:LSX 1 "")]
@@ -352,27 +388,21 @@
   [(set_attr "type" "simd_permute")
    (set_attr "mode" "<MODE>")])
 
-(define_expand "vec_unpacks_hi_v4sf"
+(define_expand "vec_unpacks_lo_v4sf"
   [(set (match_operand:V2DF 0 "register_operand" "=f")
-	(float_extend:V2DF
-	  (vec_select:V2SF
-	    (match_operand:V4SF 1 "register_operand" "f")
-	    (match_dup 2))))]
-  "ISA_HAS_LSX"
-{
-  operands[2] = loongarch_lsx_vec_parallel_const_half (V4SFmode, true/*high_p*/);
-})
+    (float_extend:V2DF
+      (vec_select:V2SF
+        (match_operand:V4SF 1 "register_operand" "f")
+        (parallel [(const_int 0) (const_int 1)]))))]
+  "ISA_HAS_LSX")
 
-(define_expand "vec_unpacks_lo_v4sf"
+(define_expand "vec_unpacks_hi_v4sf"
   [(set (match_operand:V2DF 0 "register_operand" "=f")
-	(float_extend:V2DF
-	  (vec_select:V2SF
-	    (match_operand:V4SF 1 "register_operand" "f")
-	    (match_dup 2))))]
-  "ISA_HAS_LSX"
-{
-  operands[2] = loongarch_lsx_vec_parallel_const_half (V4SFmode, false/*high_p*/);
-})
+    (float_extend:V2DF
+      (vec_select:V2SF
+        (match_operand:V4SF 1 "register_operand" "f")
+        (parallel [(const_int 2) (const_int 3)]))))]
+  "ISA_HAS_LSX")
 
 (define_expand "vec_unpacks_hi_<mode>"
   [(match_operand:<VDMODE> 0 "register_operand")
@@ -1011,7 +1041,25 @@
   [(set_attr "type" "simd_fmul")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "div<mode>3"
+(define_expand "div<mode>3"
+  [(set (match_operand:FLSX 0 "register_operand")
+    (div:FLSX (match_operand:FLSX 1 "register_operand")
+          (match_operand:FLSX 2 "register_operand")))]
+  "ISA_HAS_LSX"
+{
+  if (<MODE>mode == V4SFmode
+    && TARGET_RECIP_VEC_DIV
+    && optimize_insn_for_speed_p ()
+    && flag_finite_math_only && !flag_trapping_math
+    && flag_unsafe_math_optimizations)
+  {
+    loongarch_emit_swdivsf (operands[0], operands[1],
+           operands[2], V4SFmode);
+    DONE;
+  }
+})
+
+(define_insn "*div<mode>3"
   [(set (match_operand:FLSX 0 "register_operand" "=f")
 	(div:FLSX (match_operand:FLSX 1 "register_operand" "f")
 		  (match_operand:FLSX 2 "register_operand" "f")))]
@@ -1040,7 +1088,23 @@
   [(set_attr "type" "simd_fmadd")
    (set_attr "mode" "<MODE>")])
 
-(define_insn "sqrt<mode>2"
+(define_expand "sqrt<mode>2"
+  [(set (match_operand:FLSX 0 "register_operand")
+    (sqrt:FLSX (match_operand:FLSX 1 "register_operand")))]
+  "ISA_HAS_LSX"
+{
+  if (<MODE>mode == V4SFmode
+      && TARGET_RECIP_VEC_SQRT
+      && flag_unsafe_math_optimizations
+      && optimize_insn_for_speed_p ()
+      && flag_finite_math_only && !flag_trapping_math)
+    {
+      loongarch_emit_swrsqrtsf (operands[0], operands[1], V4SFmode, 0);
+      DONE;
+    }
+})
+
+(define_insn "*sqrt<mode>2"
   [(set (match_operand:FLSX 0 "register_operand" "=f")
 	(sqrt:FLSX (match_operand:FLSX 1 "register_operand" "f")))]
   "ISA_HAS_LSX"
@@ -1464,6 +1528,15 @@
   [(set_attr "type" "simd_fdiv")
    (set_attr "mode" "<MODE>")])
 
+(define_insn "lsx_vfrecipe_<flsxfmt>"
+  [(set (match_operand:FLSX 0 "register_operand" "=f")
+    (unspec:FLSX [(match_operand:FLSX 1 "register_operand" "f")]
+             UNSPEC_RECIPE))]
+  "ISA_HAS_LSX && flag_unsafe_math_optimizations"
+  "vfrecipe.<flsxfmt>\t%w0,%w1"
+  [(set_attr "type" "simd_fdiv")
+   (set_attr "mode" "<MODE>")])
+
 (define_insn "lsx_vfrint_<flsxfmt>"
   [(set (match_operand:FLSX 0 "register_operand" "=f")
 	(unspec:FLSX [(match_operand:FLSX 1 "register_operand" "f")]
@@ -1482,19 +1555,42 @@
   [(set_attr "type" "simd_fdiv")
    (set_attr "mode" "<MODE>")])
 
+(define_insn "lsx_vfrsqrte_<flsxfmt>"
+  [(set (match_operand:FLSX 0 "register_operand" "=f")
+    (unspec:FLSX [(match_operand:FLSX 1 "register_operand" "f")]
+             UNSPEC_RSQRTE))]
+  "ISA_HAS_LSX && flag_unsafe_math_optimizations"
+  "vfrsqrte.<flsxfmt>\t%w0,%w1"
+  [(set_attr "type" "simd_fdiv")
+   (set_attr "mode" "<MODE>")])
+
 (define_expand "rsqrt<mode>2"
   [(set (match_operand:FLSX 0 "register_operand" "=f")
     (unspec:FLSX [(match_operand:FLSX 1 "register_operand" "f")]
              UNSPEC_LSX_VFRSQRT))]
-  "ISA_HAS_LSX && flag_unsafe_math_optimizations"
+  "ISA_HAS_LSX"
 {
-  if (<MODE>mode == V4SFmode)
-    loongarch_emit_swrsqrtsf (operands[0], operands[1], V4SFmode);
-  else
-    emit_insn (gen_lsx_vfrsqrt_d (operands[0], operands[1]));
-  DONE;
+  if (<MODE>mode == V4SFmode
+      && TARGET_RECIP_VEC_RSQRT
+      && flag_unsafe_math_optimizations
+      && optimize_insn_for_speed_p ()
+      && flag_finite_math_only && !flag_trapping_math)
+    {
+      loongarch_emit_swrsqrtsf (operands[0], operands[1], V4SFmode, 1);
+      DONE;
+    }
 })
 
+(define_insn "*rsqrt<mode>2"
+  [(set (match_operand:FLSX 0 "register_operand" "=f")
+    (unspec:FLSX [(match_operand:FLSX 1 "register_operand" "f")]
+             UNSPEC_LSX_VFRSQRT))]
+  "ISA_HAS_LSX"
+  "vfrsqrt.<flsxfmt>\t%w0,%w1"
+  [(set_attr "type" "simd_fdiv")
+   (set_attr "mode" "<MODE>")])
+
+
 (define_insn "lsx_vftint_s_<ilsxfmt>_<flsxfmt>"
   [(set (match_operand:<VIMODE> 0 "register_operand" "=f")
 	(unspec:<VIMODE> [(match_operand:FLSX 1 "register_operand" "f")]
@@ -2949,8 +3045,8 @@
    (set_attr "mode" "V4SF")])
 
 (define_insn "lsx_vfrintrne_s"
-  [(set (match_operand:V4SI 0 "register_operand" "=f")
-	(unspec:V4SI [(match_operand:V4SF 1 "register_operand" "f")]
+  [(set (match_operand:V4SF 0 "register_operand" "=f")
+	(unspec:V4SF [(match_operand:V4SF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRNE_S))]
   "ISA_HAS_LSX"
   "vfrintrne.s\t%w0,%w1"
@@ -2958,8 +3054,8 @@
    (set_attr "mode" "V4SF")])
 
 (define_insn "lsx_vfrintrne_d"
-  [(set (match_operand:V2DI 0 "register_operand" "=f")
-	(unspec:V2DI [(match_operand:V2DF 1 "register_operand" "f")]
+  [(set (match_operand:V2DF 0 "register_operand" "=f")
+	(unspec:V2DF [(match_operand:V2DF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRNE_D))]
   "ISA_HAS_LSX"
   "vfrintrne.d\t%w0,%w1"
@@ -2967,8 +3063,8 @@
    (set_attr "mode" "V2DF")])
 
 (define_insn "lsx_vfrintrz_s"
-  [(set (match_operand:V4SI 0 "register_operand" "=f")
-	(unspec:V4SI [(match_operand:V4SF 1 "register_operand" "f")]
+  [(set (match_operand:V4SF 0 "register_operand" "=f")
+	(unspec:V4SF [(match_operand:V4SF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRZ_S))]
   "ISA_HAS_LSX"
   "vfrintrz.s\t%w0,%w1"
@@ -2976,8 +3072,8 @@
    (set_attr "mode" "V4SF")])
 
 (define_insn "lsx_vfrintrz_d"
-  [(set (match_operand:V2DI 0 "register_operand" "=f")
-	(unspec:V2DI [(match_operand:V2DF 1 "register_operand" "f")]
+  [(set (match_operand:V2DF 0 "register_operand" "=f")
+	(unspec:V2DF [(match_operand:V2DF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRZ_D))]
   "ISA_HAS_LSX"
   "vfrintrz.d\t%w0,%w1"
@@ -2985,8 +3081,8 @@
    (set_attr "mode" "V2DF")])
 
 (define_insn "lsx_vfrintrp_s"
-  [(set (match_operand:V4SI 0 "register_operand" "=f")
-	(unspec:V4SI [(match_operand:V4SF 1 "register_operand" "f")]
+  [(set (match_operand:V4SF 0 "register_operand" "=f")
+	(unspec:V4SF [(match_operand:V4SF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRP_S))]
   "ISA_HAS_LSX"
   "vfrintrp.s\t%w0,%w1"
@@ -2994,8 +3090,8 @@
    (set_attr "mode" "V4SF")])
 
 (define_insn "lsx_vfrintrp_d"
-  [(set (match_operand:V2DI 0 "register_operand" "=f")
-	(unspec:V2DI [(match_operand:V2DF 1 "register_operand" "f")]
+  [(set (match_operand:V2DF 0 "register_operand" "=f")
+	(unspec:V2DF [(match_operand:V2DF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRP_D))]
   "ISA_HAS_LSX"
   "vfrintrp.d\t%w0,%w1"
@@ -3003,8 +3099,8 @@
    (set_attr "mode" "V2DF")])
 
 (define_insn "lsx_vfrintrm_s"
-  [(set (match_operand:V4SI 0 "register_operand" "=f")
-	(unspec:V4SI [(match_operand:V4SF 1 "register_operand" "f")]
+  [(set (match_operand:V4SF 0 "register_operand" "=f")
+	(unspec:V4SF [(match_operand:V4SF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRM_S))]
   "ISA_HAS_LSX"
   "vfrintrm.s\t%w0,%w1"
@@ -3012,14 +3108,44 @@
    (set_attr "mode" "V4SF")])
 
 (define_insn "lsx_vfrintrm_d"
-  [(set (match_operand:V2DI 0 "register_operand" "=f")
-	(unspec:V2DI [(match_operand:V2DF 1 "register_operand" "f")]
+  [(set (match_operand:V2DF 0 "register_operand" "=f")
+	(unspec:V2DF [(match_operand:V2DF 1 "register_operand" "f")]
 		     UNSPEC_LSX_VFRINTRM_D))]
   "ISA_HAS_LSX"
   "vfrintrm.d\t%w0,%w1"
   [(set_attr "type" "simd_shift")
    (set_attr "mode" "V2DF")])
 
+;; Vector versions of the floating-point frint patterns.
+;; Expands to btrunc, ceil, floor, rint.
+(define_insn "<frint_pattern_s>v4sf2"
+ [(set (match_operand:V4SF 0 "register_operand" "=f")
+	(unspec:V4SF [(match_operand:V4SF 1 "register_operand" "f")]
+			 FRINT_S))]
+  "ISA_HAS_LSX"
+  "vfrint<frint_suffix>.s\t%w0,%w1"
+  [(set_attr "type" "simd_shift")
+   (set_attr "mode" "V4SF")])
+
+(define_insn "<frint_pattern_d>v2df2"
+ [(set (match_operand:V2DF 0 "register_operand" "=f")
+	(unspec:V2DF [(match_operand:V2DF 1 "register_operand" "f")]
+			 FRINT_D))]
+  "ISA_HAS_LSX"
+  "vfrint<frint_suffix>.d\t%w0,%w1"
+  [(set_attr "type" "simd_shift")
+   (set_attr "mode" "V2DF")])
+
+;; Expands to round.
+(define_insn "round<mode>2"
+ [(set (match_operand:FLSX 0 "register_operand" "=f")
+	(unspec:FLSX [(match_operand:FLSX 1 "register_operand" "f")]
+			 UNSPEC_LSX_VFRINT))]
+  "ISA_HAS_LSX"
+  "vfrint.<flsxfrint>\t%w0,%w1"
+  [(set_attr "type" "simd_shift")
+   (set_attr "mode" "<MODE>")])
+
 ;; Offset load and broadcast
 (define_expand "lsx_vldrepl_<lsxfmt_f>"
   [(match_operand:LSX 0 "register_operand")
diff --git a/gcc/config/loongarch/lsxintrin.h b/gcc/config/loongarch/lsxintrin.h
index a0b16d28d..2d1598536 100644
--- a/gcc/config/loongarch/lsxintrin.h
+++ b/gcc/config/loongarch/lsxintrin.h
@@ -3291,65 +3291,65 @@ __m128i __lsx_vftintrneh_l_s(__m128 _1)
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V4SI, V4SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrne_s(__m128 _1)
+__m128 __lsx_vfrintrne_s(__m128 _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrne_s((v4f32)_1);
+	return (__m128)__builtin_lsx_vfrintrne_s((v4f32)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V2DI, V2DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrne_d(__m128d _1)
+__m128d __lsx_vfrintrne_d(__m128d _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrne_d((v2f64)_1);
+	return (__m128d)__builtin_lsx_vfrintrne_d((v2f64)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V4SI, V4SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrz_s(__m128 _1)
+__m128 __lsx_vfrintrz_s(__m128 _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrz_s((v4f32)_1);
+	return (__m128)__builtin_lsx_vfrintrz_s((v4f32)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V2DI, V2DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrz_d(__m128d _1)
+__m128d __lsx_vfrintrz_d(__m128d _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrz_d((v2f64)_1);
+	return (__m128d)__builtin_lsx_vfrintrz_d((v2f64)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V4SI, V4SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrp_s(__m128 _1)
+__m128 __lsx_vfrintrp_s(__m128 _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrp_s((v4f32)_1);
+	return (__m128)__builtin_lsx_vfrintrp_s((v4f32)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V2DI, V2DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrp_d(__m128d _1)
+__m128d __lsx_vfrintrp_d(__m128d _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrp_d((v2f64)_1);
+	return (__m128d)__builtin_lsx_vfrintrp_d((v2f64)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V4SI, V4SF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrm_s(__m128 _1)
+__m128 __lsx_vfrintrm_s(__m128 _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrm_s((v4f32)_1);
+	return (__m128)__builtin_lsx_vfrintrm_s((v4f32)_1);
 }
 
 /* Assembly instruction format:          vd, vj.  */
 /* Data types in instruction templates:  V2DI, V2DF.  */
 extern __inline __attribute__((__gnu_inline__, __always_inline__, __artificial__))
-__m128i __lsx_vfrintrm_d(__m128d _1)
+__m128d __lsx_vfrintrm_d(__m128d _1)
 {
-	return (__m128i)__builtin_lsx_vfrintrm_d((v2f64)_1);
+	return (__m128d)__builtin_lsx_vfrintrm_d((v2f64)_1);
 }
 
 /* Assembly instruction format:          vd, rj, si8, idx.  */
diff --git a/gcc/config/loongarch/sync.md b/gcc/config/loongarch/sync.md
index 02e9f8d34..abc401339 100644
--- a/gcc/config/loongarch/sync.md
+++ b/gcc/config/loongarch/sync.md
@@ -29,6 +29,7 @@
   UNSPEC_COMPARE_AND_SWAP_NAND
   UNSPEC_SYNC_OLD_OP
   UNSPEC_SYNC_EXCHANGE
+  UNSPEC_ATOMIC_LOAD
   UNSPEC_ATOMIC_STORE
   UNSPEC_MEMORY_BARRIER
 ])
@@ -37,8 +38,12 @@
 (define_code_attr atomic_optab
   [(plus "add") (ior "or") (xor "xor") (and "and")])
 
+(define_mode_iterator AMO_BHWD [(QI "TARGET_uARCH_LA664")
+				(HI "TARGET_uARCH_LA664")
+				SI DI])
+
 ;; This attribute gives the format suffix for atomic memory operations.
-(define_mode_attr amo [(SI "w") (DI "d")])
+(define_mode_attr amo [(QI "b") (HI "h") (SI "w") (DI "d")])
 
 ;; <amop> expands to the name of the atomic operand that implements a
 ;; particular code.
@@ -50,7 +55,8 @@
   [(match_operand:SI 0 "const_int_operand" "")] ;; model
   ""
 {
-  if (INTVAL (operands[0]) != MEMMODEL_RELAXED)
+  enum memmodel model = memmodel_from_int (INTVAL (operands[0]));
+  if (!is_mm_relaxed (model))
     {
       rtx mem = gen_rtx_MEM (BLKmode, gen_rtx_SCRATCH (Pmode));
       MEM_VOLATILE_P (mem) = 1;
@@ -66,19 +72,50 @@
 	(unspec:BLK [(match_dup 0)] UNSPEC_MEMORY_BARRIER))
    (match_operand:SI 1 "const_int_operand" "")] ;; model
   ""
-  "dbar\t0")
+{
+  enum memmodel model = memmodel_from_int (INTVAL (operands[1]));
+  if (is_mm_consume (model))
+    return "dbar\t0x700";
+  else if (is_mm_acquire (model))
+    return "dbar\t0x14";
+  else
+    return "dbar\t0x10";
+})
 
 ;; Atomic memory operations.
 
+(define_insn "atomic_load<mode>"
+  [(set (match_operand:QHWD 0 "register_operand" "=r")
+    (unspec_volatile:QHWD
+      [(match_operand:QHWD 1 "memory_operand" "+m")
+       (match_operand:SI 2 "const_int_operand")]			;; model
+      UNSPEC_ATOMIC_LOAD))]
+  ""
+{
+  enum memmodel model = memmodel_from_int (INTVAL (operands[2]));
+  if (is_mm_relaxed (model) || is_mm_release (model))
+    return "ld.<size>\t%0,%1";
+  if (is_mm_consume (model))
+    return "ld.<size>\t%0,%1\n\tdbar\t0x700";
+  else
+    return "ld.<size>\t%0,%1\n\tdbar\t0x14";
+})
+
 ;; Implement atomic stores with amoswap.  Fall back to fences for atomic loads.
 (define_insn "atomic_store<mode>"
-  [(set (match_operand:GPR 0 "memory_operand" "+ZB")
-    (unspec_volatile:GPR
-      [(match_operand:GPR 1 "reg_or_0_operand" "rJ")
+  [(set (match_operand:QHWD 0 "memory_operand" "+m")
+    (unspec_volatile:QHWD
+      [(match_operand:QHWD 1 "reg_or_0_operand" "rJ")
        (match_operand:SI 2 "const_int_operand")]      ;; model
       UNSPEC_ATOMIC_STORE))]
   ""
-  "amswap%A2.<amo>\t$zero,%z1,%0"
+{
+  enum memmodel model = memmodel_from_int (INTVAL (operands[2]));
+  if (is_mm_relaxed (model) || is_mm_acquire (model) || is_mm_consume (model))
+    return "st.<size>\t%z1,%0";
+  else
+    return "dbar\t0x12\n\tst.<size>\t%z1,%0";
+}
   [(set (attr "length") (const_int 8))])
 
 (define_insn "atomic_<atomic_optab><mode>"
@@ -89,7 +126,18 @@
 	   (match_operand:SI 2 "const_int_operand")] ;; model
 	 UNSPEC_SYNC_OLD_OP))]
   ""
-  "am<amop>%A2.<amo>\t$zero,%z1,%0"
+  "%J2\n\tam<amop>%A2.<amo>\t$zero,%z1,%0\n\t%K2"
+  [(set (attr "length") (const_int 8))])
+
+(define_insn "atomic_add<mode>"
+  [(set (match_operand:SHORT 0 "memory_operand" "+ZB")
+	(unspec_volatile:SHORT
+	  [(plus:SHORT (match_dup 0)
+		       (match_operand:SHORT 1 "reg_or_0_operand" "rJ"))
+	   (match_operand:SI 2 "const_int_operand")] ;; model
+	 UNSPEC_SYNC_OLD_OP))]
+  "TARGET_uARCH_LA664"
+  "%J2\n\tamadd%A2.<amo>\t$zero,%z1,%0\n\t%K2"
   [(set (attr "length") (const_int 8))])
 
 (define_insn "atomic_fetch_<atomic_optab><mode>"
@@ -98,11 +146,11 @@
    (set (match_dup 1)
 	(unspec_volatile:GPR
 	  [(any_atomic:GPR (match_dup 1)
-		     (match_operand:GPR 2 "reg_or_0_operand" "rJ"))
+			   (match_operand:GPR 2 "reg_or_0_operand" "rJ"))
 	   (match_operand:SI 3 "const_int_operand")] ;; model
 	 UNSPEC_SYNC_OLD_OP))]
   ""
-  "am<amop>%A3.<amo>\t%0,%z2,%1"
+  "%J3\n\tam<amop>%A3.<amo>\t%0,%z2,%1\n\t%K3"
   [(set (attr "length") (const_int 8))])
 
 (define_insn "atomic_exchange<mode>"
@@ -114,35 +162,90 @@
    (set (match_dup 1)
 	(match_operand:GPR 2 "register_operand" "r"))]
   ""
-  "amswap%A3.<amo>\t%0,%z2,%1"
+  "%J3\n\tamswap%A3.<amo>\t%0,%z2,%1\n\t%K3"
+  [(set (attr "length") (const_int 8))])
+
+(define_insn "atomic_exchange<mode>_1"
+  [(set (match_operand:SHORT 0 "register_operand" "=&r")
+	(unspec_volatile:SHORT
+	  [(match_operand:SHORT 1 "memory_operand" "+ZB")
+	   (match_operand:SI 3 "const_int_operand")] ;; model
+	  UNSPEC_SYNC_EXCHANGE))
+   (set (match_dup 1)
+	(match_operand:SHORT 2 "register_operand" "r"))]
+  ""
+  "%J3\n\tamswap%A3.<amo>\t%0,%z2,%1\n\t%K3"
   [(set (attr "length") (const_int 8))])
 
 (define_insn "atomic_cas_value_strong<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")
-			      (match_operand:SI 4 "const_int_operand")  ;; mod_s
-			      (match_operand:SI 5 "const_int_operand")] ;; mod_f
+			      (match_operand:SI 4 "const_int_operand")]  ;; mod_s
 	 UNSPEC_COMPARE_AND_SWAP))
-   (clobber (match_scratch:GPR 6 "=&r"))]
+   (clobber (match_scratch:GPR 5 "=&r"))]
   ""
 {
-  return "%G5\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "bne\\t%0,%z2,2f\\n\\t"
-	 "or%i3\\t%6,$zero,%3\\n\\t"
-	 "sc.<amo>\\t%6,%1\\n\\t"
-	 "beq\\t$zero,%6,1b\\n\\t"
-	 "b\\t3f\\n\\t"
-	 "2:\\n\\t"
-	 "dbar\\t0x700\\n\\t"
-	 "3:\\n\\t";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[4]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("bne\t%0,%z2,2f", operands);
+      output_asm_insn ("or%i3\t%5,$zero,%3", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%5,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%5,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%5,1b", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	{
+	  output_asm_insn ("b\t3f", operands);
+	  output_asm_insn ("2:", operands);
+	  output_asm_insn ("dbar\t0x700", operands);
+	  output_asm_insn ("3:", operands);
+	}
+      else
+	output_asm_insn ("2:", operands);
+      return "";
+    }
+  else
+    return "%G4\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "bne\\t%0,%z2,2f\\n\\t"
+	   "or%i3\\t%5,$zero,%3\\n\\t"
+	   "sc.<amo>\\t%5,%1\\n\\t"
+	   "beq\\t$zero,%5,1b\\n\\t"
+	   "b\\t3f\\n\\t"
+	   "2:\\n\\t"
+	   "dbar\\t0x700\\n\\t"
+	   "3:\\n\\t";
 }
   [(set (attr "length") (const_int 32))])
 
+(define_insn "atomic_cas_value_strong<mode>_3a6000"
+  [(set (match_operand:AMO_BHWD 0 "register_operand" "=&r")
+	(match_operand:AMO_BHWD 1 "memory_operand" "+ZB"))
+   (set (match_dup 1)
+	(unspec_volatile:AMO_BHWD [(match_operand:AMO_BHWD 2 "reg_or_0_operand" "rJ")
+			      (match_operand:AMO_BHWD 3 "reg_or_0_operand" "rJ")
+			      (match_operand:SI 4 "const_int_operand")]  ;; mod_s
+	 UNSPEC_COMPARE_AND_SWAP))]
+  "TARGET_uARCH_LA664"
+  "ori\t%0,%z2,0\n\t%J4\n\tamcas%A4.<amo>\t%0,%z3,%1\n\t%K4"
+  [(set (attr "length") (const_int 32))])
+
 (define_expand "atomic_compare_and_swap<mode>"
   [(match_operand:SI 0 "register_operand" "")   ;; bool output
    (match_operand:GPR 1 "register_operand" "")  ;; val output
@@ -154,9 +257,29 @@
    (match_operand:SI 7 "const_int_operand" "")] ;; mod_f
   ""
 {
-  emit_insn (gen_atomic_cas_value_strong<mode> (operands[1], operands[2],
-						operands[3], operands[4],
-						operands[6], operands[7]));
+  rtx mod_s, mod_f;
+
+  mod_s = operands[6];
+  mod_f = operands[7];
+
+  /* Normally the succ memory model must be stronger than fail, but in the
+     unlikely event of fail being ACQUIRE and succ being RELEASE we need to
+     promote succ to ACQ_REL so that we don't lose the acquire semantics.  */
+
+  if (is_mm_acquire (memmodel_from_int (INTVAL (mod_f)))
+      && is_mm_release (memmodel_from_int (INTVAL (mod_s))))
+    mod_s = GEN_INT (MEMMODEL_ACQ_REL);
+
+  operands[6] = mod_s;
+
+  if (TARGET_uARCH_LA664)
+    emit_insn (gen_atomic_cas_value_strong<mode>_3a6000 (operands[1], operands[2],
+							 operands[3], operands[4],
+							 operands[6]));
+  else
+    emit_insn (gen_atomic_cas_value_strong<mode> (operands[1], operands[2],
+						  operands[3], operands[4],
+						  operands[6]));
 
   rtx compare = operands[1];
   if (operands[3] != const0_rtx)
@@ -223,7 +346,7 @@
 
 (define_insn "atomic_cas_value_cmp_and_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")
@@ -234,19 +357,53 @@
    (clobber (match_scratch:GPR 7 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%2\\n\\t"
-	 "bne\\t%7,%z4,2f\\n\\t"
-	 "and\\t%7,%0,%z3\\n\\t"
-	 "or%i5\\t%7,%7,%5\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b\\n\\t"
-	 "b\\t3f\\n\\t"
-	 "2:\\n\\t"
-	 "dbar\\t0x700\\n\\t"
-	 "3:\\n\\t";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%2", operands);
+      output_asm_insn ("bne\t%7,%z4,2f", operands);
+      output_asm_insn ("and\t%7,%0,%z3", operands);
+      output_asm_insn ("or%i5\t%7,%7,%5", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	{
+	  output_asm_insn ("b\t3f", operands);
+	  output_asm_insn ("2:", operands);
+	  output_asm_insn ("dbar\t0x700", operands);
+	  output_asm_insn ("3:", operands);
+	}
+      else
+	output_asm_insn ("2:", operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%2\\n\\t"
+	   "bne\\t%7,%z4,2f\\n\\t"
+	   "and\\t%7,%0,%z3\\n\\t"
+	   "or%i5\\t%7,%7,%5\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b\\n\\t"
+	   "b\\t3f\\n\\t"
+	   "2:\\n\\t"
+	   "dbar\\t0x700\\n\\t"
+	   "3:\\n\\t";
 }
   [(set (attr "length") (const_int 40))])
 
@@ -261,37 +418,59 @@
    (match_operand:SI 7 "const_int_operand" "")] ;; mod_f
   ""
 {
-  union loongarch_gen_fn_ptrs generator;
-  generator.fn_7 = gen_atomic_cas_value_cmp_and_7_si;
-  loongarch_expand_atomic_qihi (generator, operands[1], operands[2],
-				operands[3], operands[4], operands[7]);
+  rtx mod_s, mod_f;
 
-  rtx compare = operands[1];
-  if (operands[3] != const0_rtx)
-    {
-      machine_mode mode = GET_MODE (operands[3]);
-      rtx op1 = convert_modes (SImode, mode, operands[1], true);
-      rtx op3 = convert_modes (SImode, mode, operands[3], true);
-      rtx difference = gen_rtx_MINUS (SImode, op1, op3);
-      compare = gen_reg_rtx (SImode);
-      emit_insn (gen_rtx_SET (compare, difference));
-    }
+  mod_s = operands[6];
+  mod_f = operands[7];
 
-  if (word_mode != <MODE>mode)
+  /* Normally the succ memory model must be stronger than fail, but in the
+     unlikely event of fail being ACQUIRE and succ being RELEASE we need to
+     promote succ to ACQ_REL so that we don't lose the acquire semantics.  */
+
+  if (is_mm_acquire (memmodel_from_int (INTVAL (mod_f)))
+      && is_mm_release (memmodel_from_int (INTVAL (mod_s))))
+    mod_s = GEN_INT (MEMMODEL_ACQ_REL);
+
+  operands[6] = mod_s;
+
+  if (TARGET_uARCH_LA664)
+    emit_insn (gen_atomic_cas_value_strong<mode>_3a6000 (operands[1], operands[2],
+							 operands[3], operands[4],
+							 operands[6]));
+  else
     {
-      rtx reg = gen_reg_rtx (word_mode);
-      emit_insn (gen_rtx_SET (reg, gen_rtx_SIGN_EXTEND (word_mode, compare)));
-      compare = reg;
+      union loongarch_gen_fn_ptrs generator;
+      generator.fn_7 = gen_atomic_cas_value_cmp_and_7_si;
+      loongarch_expand_atomic_qihi (generator, operands[1], operands[2],
+				    operands[3], operands[4], operands[6]);
     }
 
-  emit_insn (gen_rtx_SET (operands[0],
-			  gen_rtx_EQ (SImode, compare, const0_rtx)));
+      rtx compare = operands[1];
+      if (operands[3] != const0_rtx)
+	{
+	  machine_mode mode = GET_MODE (operands[3]);
+	  rtx op1 = convert_modes (SImode, mode, operands[1], true);
+	  rtx op3 = convert_modes (SImode, mode, operands[3], true);
+	  rtx difference = gen_rtx_MINUS (SImode, op1, op3);
+	  compare = gen_reg_rtx (SImode);
+	  emit_insn (gen_rtx_SET (compare, difference));
+	}
+
+      if (word_mode != <MODE>mode)
+	{
+	  rtx reg = gen_reg_rtx (word_mode);
+	  emit_insn (gen_rtx_SET (reg, gen_rtx_SIGN_EXTEND (word_mode, compare)));
+	  compare = reg;
+	}
+
+      emit_insn (gen_rtx_SET (operands[0],
+			      gen_rtx_EQ (SImode, compare, const0_rtx)));
   DONE;
 })
 
 (define_insn "atomic_cas_value_add_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")				;; res
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")	;; mask
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")	;; inverted_mask
@@ -303,22 +482,46 @@
    (clobber (match_scratch:GPR 8 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%3\\n\\t"
-	 "add.w\\t%8,%0,%z5\\n\\t"
-	 "and\\t%8,%8,%z2\\n\\t"
-	 "or%i8\\t%7,%7,%8\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%3", operands);
+      output_asm_insn ("add.w\t%8,%0,%z5", operands);
+      output_asm_insn ("and\t%8,%8,%z2", operands);
+      output_asm_insn ("or%i8\t%7,%7,%8", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b",operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%3\\n\\t"
+	   "add.w\\t%8,%0,%z5\\n\\t"
+	   "and\\t%8,%8,%z2\\n\\t"
+	   "or%i8\\t%7,%7,%8\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b";
 }
 
   [(set (attr "length") (const_int 32))])
 
 (define_insn "atomic_cas_value_sub_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")				;; res
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")	;; mask
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")	;; inverted_mask
@@ -330,21 +533,45 @@
    (clobber (match_scratch:GPR 8 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%3\\n\\t"
-	 "sub.w\\t%8,%0,%z5\\n\\t"
-	 "and\\t%8,%8,%z2\\n\\t"
-	 "or%i8\\t%7,%7,%8\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%3", operands);
+      output_asm_insn ("sub.w\t%8,%0,%z5", operands);
+      output_asm_insn ("and\t%8,%8,%z2", operands);
+      output_asm_insn ("or%i8\t%7,%7,%8", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b", operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%3\\n\\t"
+	   "sub.w\\t%8,%0,%z5\\n\\t"
+	   "and\\t%8,%8,%z2\\n\\t"
+	   "or%i8\\t%7,%7,%8\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b";
 }
   [(set (attr "length") (const_int 32))])
 
 (define_insn "atomic_cas_value_and_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")				;; res
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")	;; mask
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")	;; inverted_mask
@@ -356,21 +583,45 @@
    (clobber (match_scratch:GPR 8 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%3\\n\\t"
-	 "and\\t%8,%0,%z5\\n\\t"
-	 "and\\t%8,%8,%z2\\n\\t"
-	 "or%i8\\t%7,%7,%8\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%3", operands);
+      output_asm_insn ("and\t%8,%0,%z5", operands);
+      output_asm_insn ("and\t%8,%8,%z2", operands);
+      output_asm_insn ("or%i8\t%7,%7,%8", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b", operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%3\\n\\t"
+	   "and\\t%8,%0,%z5\\n\\t"
+	   "and\\t%8,%8,%z2\\n\\t"
+	   "or%i8\\t%7,%7,%8\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b";
 }
   [(set (attr "length") (const_int 32))])
 
 (define_insn "atomic_cas_value_xor_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")				;; res
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")	;; mask
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")	;; inverted_mask
@@ -382,22 +633,46 @@
    (clobber (match_scratch:GPR 8 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%3\\n\\t"
-	 "xor\\t%8,%0,%z5\\n\\t"
-	 "and\\t%8,%8,%z2\\n\\t"
-	 "or%i8\\t%7,%7,%8\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%3", operands);
+      output_asm_insn ("xor\t%8,%0,%z5", operands);
+      output_asm_insn ("and\t%8,%8,%z2", operands);
+      output_asm_insn ("or%i8\t%7,%7,%8", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b", operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%3\\n\\t"
+	   "xor\\t%8,%0,%z5\\n\\t"
+	   "and\\t%8,%8,%z2\\n\\t"
+	   "or%i8\\t%7,%7,%8\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b";
 }
 
   [(set (attr "length") (const_int 32))])
 
 (define_insn "atomic_cas_value_or_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")				;; res
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")	;; mask
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")	;; inverted_mask
@@ -409,22 +684,46 @@
    (clobber (match_scratch:GPR 8 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%3\\n\\t"
-	 "or\\t%8,%0,%z5\\n\\t"
-	 "and\\t%8,%8,%z2\\n\\t"
-	 "or%i8\\t%7,%7,%8\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%3", operands);
+      output_asm_insn ("or\t%8,%0,%z5", operands);
+      output_asm_insn ("and\t%8,%8,%z2", operands);
+      output_asm_insn ("or%i8\t%7,%7,%8", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b", operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%3\\n\\t"
+	   "or\\t%8,%0,%z5\\n\\t"
+	   "and\\t%8,%8,%z2\\n\\t"
+	   "or%i8\\t%7,%7,%8\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b";
 }
 
   [(set (attr "length") (const_int 32))])
 
 (define_insn "atomic_cas_value_nand_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")				;; res
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")	;; mask
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")	;; inverted_mask
@@ -436,21 +735,45 @@
    (clobber (match_scratch:GPR 8 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%3\\n\\t"
-	 "and\\t%8,%0,%z5\\n\\t"
-	 "xor\\t%8,%8,%z2\\n\\t"
-	 "or%i8\\t%7,%7,%8\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beq\\t$zero,%7,1b";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%3", operands);
+      output_asm_insn ("and\t%8,%0,%z5", operands);
+      output_asm_insn ("xor\t%8,%8,%z2", operands);
+      output_asm_insn ("or%i8\t%7,%7,%8", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beq\t$zero,%7,1b", operands);
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%3\\n\\t"
+	   "and\\t%8,%0,%z5\\n\\t"
+	   "xor\\t%8,%8,%z2\\n\\t"
+	   "or%i8\\t%7,%7,%8\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beq\\t$zero,%7,1b";
 }
   [(set (attr "length") (const_int 32))])
 
 (define_insn "atomic_cas_value_exchange_7_<mode>"
   [(set (match_operand:GPR 0 "register_operand" "=&r")
-	(match_operand:GPR 1 "memory_operand" "+ZC"))
+	(match_operand:GPR 1 "memory_operand" "+ZB"))
    (set (match_dup 1)
 	(unspec_volatile:GPR [(match_operand:GPR 2 "reg_or_0_operand" "rJ")
 			      (match_operand:GPR 3 "reg_or_0_operand" "rJ")
@@ -461,13 +784,36 @@
    (clobber (match_scratch:GPR 7 "=&r"))]
   ""
 {
-  return "%G6\\n\\t"
-	 "1:\\n\\t"
-	 "ll.<amo>\\t%0,%1\\n\\t"
-	 "and\\t%7,%0,%z3\\n\\t"
-	 "or%i5\\t%7,%7,%5\\n\\t"
-	 "sc.<amo>\\t%7,%1\\n\\t"
-	 "beqz\\t%7,1b\\n\\t";
+  if (TARGET_uARCH_LA664)
+    {
+      enum memmodel model = memmodel_from_int (INTVAL (operands[6]));
+      output_asm_insn ("1:",operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_release (model))
+	output_asm_insn ("ll.<amo>\t%0,%1", operands);
+      else
+	output_asm_insn ("llacq.<amo>\t%0,%1", operands);
+
+      output_asm_insn ("and\t%7,%0,%z3", operands);
+      output_asm_insn ("or%i5\t%7,%7,%5", operands);
+
+      if (is_mm_relaxed (model) || is_mm_consume (model) || is_mm_acquire (model))
+	output_asm_insn ("sc.<amo>\t%7,%1", operands);
+      else
+	output_asm_insn ("screl.<amo>\t%7,%1", operands);
+
+      output_asm_insn ("beqz\t%7,1b", operands);
+
+      return "";
+    }
+  else
+    return "%G6\\n\\t"
+	   "1:\\n\\t"
+	   "ll.<amo>\\t%0,%1\\n\\t"
+	   "and\\t%7,%0,%z3\\n\\t"
+	   "or%i5\\t%7,%7,%5\\n\\t"
+	   "sc.<amo>\\t%7,%1\\n\\t"
+	   "beqz\\t%7,1b\\n\\t";
 }
   [(set (attr "length") (const_int 20))])
 
@@ -481,13 +827,31 @@
 	(match_operand:SHORT 2 "register_operand"))]
   ""
 {
-  union loongarch_gen_fn_ptrs generator;
-  generator.fn_7 = gen_atomic_cas_value_exchange_7_si;
-  loongarch_expand_atomic_qihi (generator, operands[0], operands[1],
-				const0_rtx, operands[2], operands[3]);
+  if (TARGET_uARCH_LA664)
+    emit_insn (gen_atomic_exchange<mode>_1 (operands[0], operands[1], operands[2], operands[3]));
+  else
+    {
+      union loongarch_gen_fn_ptrs generator;
+      generator.fn_7 = gen_atomic_cas_value_exchange_7_si;
+      loongarch_expand_atomic_qihi (generator, operands[0], operands[1],
+				    const0_rtx, operands[2], operands[3]);
+    }
   DONE;
 })
 
+(define_insn "atomic_fetch_add<mode>_1"
+  [(set (match_operand:SHORT 0 "register_operand" "=&r")
+	(match_operand:SHORT 1 "memory_operand" "+ZB"))
+   (set (match_dup 1)
+	(unspec_volatile:SHORT
+	  [(plus:SHORT (match_dup 1)
+		     (match_operand:SHORT 2 "reg_or_0_operand" "rJ"))
+	   (match_operand:SI 3 "const_int_operand")] ;; model
+	 UNSPEC_SYNC_OLD_OP))]
+  ""
+  "%J3\n\tamadd%A3.<amo>\t%0,%z2,%1\n\t%K3"
+  [(set (attr "length") (const_int 8))])
+
 (define_expand "atomic_fetch_add<mode>"
   [(set (match_operand:SHORT 0 "register_operand" "=&r")
 	(match_operand:SHORT 1 "memory_operand" "+ZB"))
@@ -499,10 +863,16 @@
 	 UNSPEC_SYNC_OLD_OP))]
   ""
 {
-  union loongarch_gen_fn_ptrs generator;
-  generator.fn_7 = gen_atomic_cas_value_add_7_si;
-  loongarch_expand_atomic_qihi (generator, operands[0], operands[1],
-				operands[1], operands[2], operands[3]);
+  if (TARGET_uARCH_LA664)
+    emit_insn (gen_atomic_fetch_add<mode>_1 (operands[0], operands[1],
+					     operands[2], operands[3]));
+  else
+    {
+      union loongarch_gen_fn_ptrs generator;
+      generator.fn_7 = gen_atomic_cas_value_add_7_si;
+      loongarch_expand_atomic_qihi (generator, operands[0], operands[1],
+				    operands[1], operands[2], operands[3]);
+    }
   DONE;
 })
 
diff --git a/gcc/config/loongarch/t-linux b/gcc/config/loongarch/t-linux
index 25ebfb249..5ecf814fa 100644
--- a/gcc/config/loongarch/t-linux
+++ b/gcc/config/loongarch/t-linux
@@ -47,7 +47,7 @@ specs: specs.install
 
 # Remove lib_build_self_specs before regression tests.
 .PHONY: remove-lib-specs
-check check-host check-target $(CHECK_TARGETS): remove-lib-specs
+check check-host check-target $(CHECK_TARGETS) $(lang_checks): remove-lib-specs
 remove-lib-specs:
 	-mv -f specs.install specs 2>/dev/null
 
diff --git a/gcc/config/loongarch/t-loongarch b/gcc/config/loongarch/t-loongarch
index 9d32fbcf6..e34512114 100644
--- a/gcc/config/loongarch/t-loongarch
+++ b/gcc/config/loongarch/t-loongarch
@@ -20,6 +20,10 @@
 LA_MULTIARCH_TRIPLET = $(patsubst LA_MULTIARCH_TRIPLET=%,%,$\
 $(filter LA_MULTIARCH_TRIPLET=%,$(tm_defines)))
 
+OPTIONS_H_EXTRA += $(srcdir)/config/loongarch/loongarch-def.h \
+		   $(srcdir)/config/loongarch/loongarch-tune.h \
+		   $(srcdir)/config/loongarch/loongarch-driver.h
+
 # String definition header
 LA_STR_H = $(srcdir)/config/loongarch/loongarch-str.h
 $(LA_STR_H): s-loongarch-str ; @true
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic.exp b/gcc/testsuite/gcc.target/loongarch/atomic/atomic.exp
new file mode 100644
index 000000000..bebc00047
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic.exp
@@ -0,0 +1,40 @@
+# Copyright (C) 2020-2022 Free Software Foundation, Inc.
+
+# This program is free software; you can redistribute it and/or modify
+# it under the terms of the GNU General Public License as published by
+# the Free Software Foundation; either version 3 of the License, or
+# (at your option) any later version.
+#
+# This program is distributed in the hope that it will be useful,
+# but WITHOUT ANY WARRANTY; without even the implied warranty of
+# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
+# GNU General Public License for more details.
+#
+# You should have received a copy of the GNU General Public License
+# along with GCC; see the file COPYING3.  If not see
+# <http://www.gnu.org/licenses/>.
+
+# GCC testsuite that uses the `dg.exp' driver.
+
+# Exit immediately if this isn't a Loongarch target.
+if ![istarget loongarch*-*-*] then {
+  return
+}
+
+# Load support procs.
+load_lib gcc-dg.exp
+
+# If a testcase doesn't have special options, use these.
+global DEFAULT_CFLAGS
+if ![info exists DEFAULT_CFLAGS] then {
+    set DEFAULT_CFLAGS " "
+}
+
+# Initialize `dg'.
+dg-init
+
+# Main loop.
+dg-runtest [lsort [glob -nocomplain $srcdir/$subdir/*.\[cS\]]] \
+	"" $DEFAULT_CFLAGS
+# All done.
+dg-finish
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_add_fetch.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_add_fetch.c
new file mode 100644
index 000000000..8c2b2470b
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_add_fetch.c
@@ -0,0 +1,16 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=la664" } */
+/* { dg-final { scan-assembler "amadd\\.b" } } */
+/* { dg-final { scan-assembler "amadd\\.h" } } */
+
+void
+atomic_add_fetch_b (char *src)
+{
+  __atomic_add_fetch (src, 1, __ATOMIC_RELEASE);
+}
+
+void
+atomic_add_fetch_h (short *src)
+{
+  __atomic_add_fetch (src, 1, __ATOMIC_RELEASE);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_compare_exchange.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_compare_exchange.c
new file mode 100644
index 000000000..8a071732f
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_compare_exchange.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=loongarch64" } */
+/* { dg-final { scan-assembler "dbar\t0x11" } } */
+
+void
+atomic_compare_exchange_w (int *ptr, int *expected, int *desired)
+{
+  __atomic_compare_exchange (ptr, expected, desired, 0, __ATOMIC_RELEASE, __ATOMIC_ACQUIRE);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_compare_exchange_n.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_compare_exchange_n.c
new file mode 100644
index 000000000..280c99aa1
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_compare_exchange_n.c
@@ -0,0 +1,59 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=la664 -mabi=lp64d" } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_b:.*amcas\\.b.*atomic_compare_exchange_n_b" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_h:.*amcas\\.h.*atomic_compare_exchange_n_h" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_w:.*amcas\\.w.*atomic_compare_exchange_n_w" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_d:.*amcas\\.d.*atomic_compare_exchange_n_d" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_db_b:.*amcas_db\\.b.*atomic_compare_exchange_n_db_b" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_db_h:.*amcas_db\\.h.*atomic_compare_exchange_n_db_h" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_db_w:.*amcas_db\\.w.*atomic_compare_exchange_n_db_w" } } */
+/* { dg-final { scan-assembler "atomic_compare_exchange_n_db_d:.*amcas_db\\.d.*atomic_compare_exchange_n_db_d" } } */
+
+void
+atomic_compare_exchange_n_b (char *old, char *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQUIRE, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_h (short *old, short *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQUIRE, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_w (int *old, int *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQUIRE, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_d (long *old, long *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQUIRE, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_db_b (char *old, char *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQ_REL, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_db_h (short *old, short *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQ_REL, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_db_w (int *old, int *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQ_REL, __ATOMIC_ACQUIRE);
+}
+
+void
+atomic_compare_exchange_n_db_d (long *old, long *exp)
+{
+  __atomic_compare_exchange_n (old, exp, 1, 0, __ATOMIC_ACQ_REL, __ATOMIC_ACQUIRE);
+}
+
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_load.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_load.c
new file mode 100644
index 000000000..57f46996d
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_load.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "dbar\t0x14" } } */
+
+void
+atomic_load (int *src, int *dst)
+{
+  __atomic_load (src, dst, __ATOMIC_ACQUIRE);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_store.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_store.c
new file mode 100644
index 000000000..83cd6eb2c
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_store.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "dbar\t0x12" } } */
+
+void
+atomic_store (int *src, int *dst)
+{
+  __atomic_store (src, dst, __ATOMIC_RELEASE);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_swap.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_swap.c
new file mode 100644
index 000000000..462f19a1c
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_swap.c
@@ -0,0 +1,17 @@
+/* { dg-do compile } */
+/* { dg-options "-O2 -march=la664" } */
+/* { dg-final { scan-assembler "amswap_db\\.b" } } */
+/* { dg-final { scan-assembler "amswap_db\\.h" } } */
+
+void
+atomic_exchange_b (char *dst, char *src, char *ret)
+{
+  __atomic_exchange (dst, src, ret, __ATOMIC_ACQ_REL);
+}
+
+void
+atomic_exchange_h (short *dst, short *src, short *ret)
+{
+  __atomic_exchange (dst, src, ret, __ATOMIC_SEQ_CST);
+}
+
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence1.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence1.c
new file mode 100644
index 000000000..838ac7ac0
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence1.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-not "dbar" } } */
+
+void
+atomic_thread_fence (void)
+{
+  __atomic_thread_fence (__ATOMIC_RELAXED);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence2.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence2.c
new file mode 100644
index 000000000..8349ea8d4
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence2.c
@@ -0,0 +1,9 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "dbar\t0x14" } } */
+
+void
+atomic_thread_fence (void)
+{
+  __atomic_thread_fence (__ATOMIC_ACQUIRE);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence3.c b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence3.c
new file mode 100644
index 000000000..c2472637f
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/atomic/atomic_thread_fence3.c
@@ -0,0 +1,15 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler-times "dbar\t0x10" 2} } */
+
+void
+atomic_thread_fence (void)
+{
+  __atomic_thread_fence (__ATOMIC_ACQ_REL);
+}
+
+void
+atomic_thread_fence_rel (void)
+{
+  __atomic_thread_fence (__ATOMIC_RELEASE);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/blk-move-opt.c b/gcc/testsuite/gcc.target/loongarch/blk-move-opt.c
new file mode 100644
index 000000000..592c3c921
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/blk-move-opt.c
@@ -0,0 +1,24 @@
+/* Considering vector alignment memory access, use 4 consecutive scalar
+   ld.d/st.d instead of xvld/xvst to implement 32B BLK move.
+   Especially effective for SPEC2017 538.  */
+/* { dg-do compile } */
+/* { dg-options "-O3 -mlasx" } */
+/* { dg-final { scan-assembler-not "xvld" } } */
+/* { dg-final { scan-assembler-not "xvst" } } */
+
+typedef struct _SA
+{
+  long a;
+  long b;
+  long c;
+  long d;
+} SA;
+
+extern SA aa;
+extern SA foo (SA);
+
+void
+test (SA s)
+{
+  foo (s);
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/insn_correctness_check.c b/gcc/testsuite/gcc.target/loongarch/insn_correctness_check.c
index fa24ed4dd..b273ba53f 100644
--- a/gcc/testsuite/gcc.target/loongarch/insn_correctness_check.c
+++ b/gcc/testsuite/gcc.target/loongarch/insn_correctness_check.c
@@ -3136,12 +3136,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -4254,10 +4254,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000003;
@@ -4610,12 +4612,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000303;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000001;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000001;
@@ -6702,10 +6708,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -7035,12 +7043,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x1e18000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x1e18000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x1e18000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xbff0000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0xbff0000000000000;
@@ -10050,10 +10058,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0xff02ff1bff02ff23;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000ffffff02fff4;
-  *((unsigned long*)& __m128i_result[1]) = 0xff02ff1bff02ff23;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0xff02ff1bff02ff23;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -10304,12 +10312,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000ffff00010000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000ffff00010000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x3ff0000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x3ff0000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000004;
@@ -11873,12 +11881,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x000000ff000000ff;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -13109,10 +13117,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffffffffffffff;
@@ -14119,10 +14127,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0xefffffff;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x00000000efffffff;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0xefffffff;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x1c1b1a191c1b1a19;
   *((unsigned long*)& __m256i_op0[2]) = 0x1c1b1a191c1b1a19;
@@ -14681,10 +14691,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -18024,12 +18034,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffffff;
@@ -18584,12 +18594,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffff0000;
   *((unsigned long*)& __m128i_op0[0]) = 0x000000000001fffe;
@@ -18955,12 +18965,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xfffffffe;
   *((int*)& __m256_op0[1]) = 0xffffffff;
   *((int*)& __m256_op0[0]) = 0xfffffffe;
-  *((unsigned long*)& __m256i_result[3]) = 0xfffffffffffffffe;
-  *((unsigned long*)& __m256i_result[2]) = 0xfffffffefffffefc;
-  *((unsigned long*)& __m256i_result[1]) = 0xfffffffffffffffe;
-  *((unsigned long*)& __m256i_result[0]) = 0xfffffffffffffffe;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xffffffff;
+  *((int*)& __m256_result[6]) = 0xfffffffe;
+  *((int*)& __m256_result[5]) = 0xfffffffe;
+  *((int*)& __m256_result[4]) = 0xfffffefc;
+  *((int*)& __m256_result[3]) = 0xffffffff;
+  *((int*)& __m256_result[2]) = 0xfffffffe;
+  *((int*)& __m256_result[1]) = 0xffffffff;
+  *((int*)& __m256_result[0]) = 0xfffffffe;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0x000000000000ffff;
   *((unsigned long*)& __m256d_op0[2]) = 0x0209fefb08140000;
@@ -20711,10 +20725,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000002000;
   *((unsigned long*)& __m128d_op0[0]) = 0xfffc002000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0xfffc002000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0xfffc002000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x1717171717171717;
   *((unsigned long*)& __m256i_op0[2]) = 0x1717171717171717;
@@ -21802,12 +21816,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00080000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffffffffff8c80;
@@ -22191,10 +22209,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -23516,12 +23534,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrne_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -24288,10 +24310,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x9c9c9c9c00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x8000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x8000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((int*)& __m128_op0[3]) = 0x00000000;
   *((int*)& __m128_op0[2]) = 0x00000000;
@@ -24820,12 +24842,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -26938,10 +26964,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000010;
@@ -27074,12 +27100,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x36aaaaac;
   *((int*)& __m256_op0[1]) = 0x55555555;
   *((int*)& __m256_op0[0]) = 0xaaaaaaac;
-  *((unsigned long*)& __m256i_result[3]) = 0x555555553f800000;
-  *((unsigned long*)& __m256i_result[2]) = 0x5555555580000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x555555553f800000;
-  *((unsigned long*)& __m256i_result[0]) = 0x5555555580000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x55555555;
+  *((int*)& __m256_result[6]) = 0x3f800000;
+  *((int*)& __m256_result[5]) = 0x55555555;
+  *((int*)& __m256_result[4]) = 0x80000000;
+  *((int*)& __m256_result[3]) = 0x55555555;
+  *((int*)& __m256_result[2]) = 0x3f800000;
+  *((int*)& __m256_result[1]) = 0x55555555;
+  *((int*)& __m256_result[0]) = 0x80000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000010;
@@ -27700,10 +27730,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -28227,12 +28259,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -28421,10 +28457,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((int*)& __m256_op0[7]) = 0x00000000;
   *((int*)& __m256_op0[6]) = 0x00000000;
@@ -29556,12 +29592,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -29856,12 +29892,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xfffffefefffffefe;
   *((unsigned long*)& __m256d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0xfffffefe00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xfffffefefffffefe;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xfffffefe00000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[2]) = 0xfffffefefffffefe;
+  *((unsigned long*)& __m256d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[0]) = 0xfffffefe00000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -30375,12 +30411,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xfffffefefffffefe;
@@ -30681,10 +30717,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000001;
   *((unsigned long*)& __m128d_op0[0]) = 0x6a57a30ff0000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x6a57a30ff0000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x6a57a30ff0000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffffffffffffff;
@@ -31097,10 +31133,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   long_op0 = 0x0000000000000400;
   *((unsigned long*)& __m128i_result[1]) = 0x0000000000000400;
@@ -31910,12 +31946,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000800080008000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000800080008000;
@@ -33868,12 +33904,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[2]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[0]) = 0xffffffffffffffff;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000005d5d;
@@ -34341,10 +34377,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000001300000013;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffffffffffffff;
@@ -35154,12 +35190,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x5d637d043bc4fc43;
   *((unsigned long*)& __m256d_op0[1]) = 0x01dcc2dce31bc35d;
   *((unsigned long*)& __m256d_op0[0]) = 0x5e041d245b85fc43;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x5d637d043bc4fc43;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x5e041d245b85fc43;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x5d637d043bc4fc43;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x5e041d245b85fc43;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000001;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000001;
@@ -36431,10 +36467,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x3c992b2e;
   *((int*)& __m128_op0[1]) = 0xffffffff;
   *((int*)& __m128_op0[0]) = 0xffff730f;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffff00000000;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffff730f;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xffffffff;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0xffffffff;
+  *((int*)& __m128_result[0]) = 0xffff730f;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffffffe5;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffffe5;
@@ -38946,12 +38984,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0001ffe20001fefd;
   *((unsigned long*)& __m256d_op0[1]) = 0x0001009a000100fd;
   *((unsigned long*)& __m256d_op0[0]) = 0x0001ff640001fefd;
-  *((unsigned long*)& __m256i_result[3]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x3ff0000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x3ff0000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000c2f90000bafa;
   *((unsigned long*)& __m128i_op0[0]) = 0x8000c2fa8000c2fa;
@@ -39648,10 +39686,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrm_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -39780,10 +39820,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -39990,12 +40030,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xbb954b00;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffc74180000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0xffff884580000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xffffc741;
+  *((int*)& __m256_result[6]) = 0x80000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0xffff8845;
+  *((int*)& __m256_result[2]) = 0x80000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -41161,10 +41205,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x98ff98ff220e220d;
   *((unsigned long*)& __m128d_op0[0]) = 0xa2e1a2601ff01ff0;
-  *((unsigned long*)& __m128i_result[1]) = 0x8000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x8000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x8000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x8000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000082a54290;
   *((unsigned long*)& __m256i_op0[2]) = 0x00000000028aa700;
@@ -41242,10 +41286,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0xe0404041e0404041;
   *((unsigned long*)& __m128d_op0[0]) = 0xe0404041e0404041;
-  *((unsigned long*)& __m128i_result[1]) = 0xe0404041e0404041;
-  *((unsigned long*)& __m128i_result[0]) = 0xe0404041e0404041;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0xe0404041e0404041;
+  *((unsigned long*)& __m128d_result[0]) = 0xe0404041e0404041;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000002a54290;
@@ -43717,12 +43761,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x000000040000ffca;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000800000098;
   *((unsigned long*)& __m256d_op0[0]) = 0x000000040000ff79;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((int*)& __m256_op0[7]) = 0x00000000;
   *((int*)& __m256_op0[6]) = 0x04000000;
@@ -43904,12 +43948,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[2]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[0]) = 0xffffffffffffffff;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x7fff7fff7fff7fff;
   *((unsigned long*)& __m128i_op0[0]) = 0x000000010000003f;
@@ -46419,12 +46463,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -47840,12 +47884,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xffffffff;
   *((int*)& __m256_op0[1]) = 0x0000ffff;
   *((int*)& __m256_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0x00000000ffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0x00000000ffffffff;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xffffffff;
+  *((int*)& __m256_result[6]) = 0xffffffff;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0xffffffff;
+  *((int*)& __m256_result[3]) = 0xffffffff;
+  *((int*)& __m256_result[2]) = 0xffffffff;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0xffffffff;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000ffffffffffff;
@@ -49038,10 +49086,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x00007fff00007fff;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x77777777f7777777;
   *((unsigned long*)& __m256i_op0[2]) = 0xf777777777777777;
@@ -53281,10 +53329,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00130013;
   *((int*)& __m128_op0[1]) = 0x00130013;
   *((int*)& __m128_op0[0]) = 0x00130013;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -54482,12 +54532,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffff0000ffff0000;
   *((unsigned long*)& __m128i_op0[0]) = 0xffff000000000000;
@@ -56604,12 +56654,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -56838,12 +56892,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -58328,12 +58386,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x7c007c007c007c00;
   *((unsigned long*)& __m256d_op0[1]) = 0x7c007c007c007c00;
   *((unsigned long*)& __m256d_op0[0]) = 0x7c007c007c007c00;
-  *((unsigned long*)& __m256i_result[3]) = 0x7c007c007c007c00;
-  *((unsigned long*)& __m256i_result[2]) = 0x7c007c007c007c00;
-  *((unsigned long*)& __m256i_result[1]) = 0x7c007c007c007c00;
-  *((unsigned long*)& __m256i_result[0]) = 0x7c007c007c007c00;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x7c007c007c007c00;
+  *((unsigned long*)& __m256d_result[2]) = 0x7c007c007c007c00;
+  *((unsigned long*)& __m256d_result[1]) = 0x7c007c007c007c00;
+  *((unsigned long*)& __m256d_result[0]) = 0x7c007c007c007c00;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xfffd000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -58550,12 +58608,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x0001c4e8;
   *((int*)& __m256_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x00000000ffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x00000000ffffffff;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0xffffffff;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0xffffffff;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0001c4e8ffffffff;
@@ -59454,12 +59516,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_result[1]) = 0xecececececececec;
   *((unsigned long*)& __m128i_result[0]) = 0xecececececececec;
@@ -59522,12 +59584,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[2]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[0]) = 0xffffffffffffffff;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -61770,12 +61832,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x01fc03fc01fc03fc;
   *((unsigned long*)& __m256d_op0[1]) = 0xfffffffffffffffc;
   *((unsigned long*)& __m256d_op0[0]) = 0x01fc03fc01fc03fc;
-  *((unsigned long*)& __m256i_result[3]) = 0xfffffffffffffffc;
-  *((unsigned long*)& __m256i_result[2]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0xfffffffffffffffc;
-  *((unsigned long*)& __m256i_result[0]) = 0x3ff0000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xfffffffffffffffc;
+  *((unsigned long*)& __m256d_result[2]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0xfffffffffffffffc;
+  *((unsigned long*)& __m256d_result[0]) = 0x3ff0000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0100000001000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0100000001000000;
@@ -65438,10 +65500,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x20202020;
   *((int*)& __m128_op0[1]) = 0x20202020;
   *((int*)& __m128_op0[0]) = 0x20207fff;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((int*)& __m256_op0[7]) = 0x00000000;
   *((int*)& __m256_op0[6]) = 0x00000000;
@@ -65624,12 +65688,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -66575,12 +66643,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x80000000;
   *((int*)& __m256_op0[1]) = 0xffffffff;
   *((int*)& __m256_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0x8000000080000000;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0x8000000080000000;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x80000000;
+  *((int*)& __m256_result[6]) = 0x80000000;
+  *((int*)& __m256_result[5]) = 0xffffffff;
+  *((int*)& __m256_result[4]) = 0xffffffff;
+  *((int*)& __m256_result[3]) = 0x80000000;
+  *((int*)& __m256_result[2]) = 0x80000000;
+  *((int*)& __m256_result[1]) = 0xffffffff;
+  *((int*)& __m256_result[0]) = 0xffffffff;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((int*)& __m128_op0[3]) = 0x00000001;
   *((int*)& __m128_op0[2]) = 0xca02f854;
@@ -67018,12 +67090,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xffffffff;
   *((int*)& __m256_op0[1]) = 0xffffffff;
   *((int*)& __m256_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xffffffff;
+  *((int*)& __m256_result[6]) = 0xffffffff;
+  *((int*)& __m256_result[5]) = 0xffffffff;
+  *((int*)& __m256_result[4]) = 0xffffffff;
+  *((int*)& __m256_result[3]) = 0xffffffff;
+  *((int*)& __m256_result[2]) = 0xffffffff;
+  *((int*)& __m256_result[1]) = 0xffffffff;
+  *((int*)& __m256_result[0]) = 0xffffffff;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffffffffffffff;
@@ -67057,10 +67133,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000001;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000016;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffffb4ff;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffb4ff;
@@ -68283,10 +68361,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x17161514;
   *((int*)& __m128_op0[1]) = 0x16151413;
   *((int*)& __m128_op0[0]) = 0x15141312;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000ffffffff0000;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffff00;
@@ -68551,12 +68631,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xffffffff;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0x00000000ffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0x00000000ffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0x00000000ffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0x00000000ffffffff;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0xffffffff;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0xffffffff;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0xffffffff;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0xffffffff;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000008a0000008a;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000008900000009;
@@ -69153,10 +69237,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0xffffff00;
   *((int*)& __m128_op0[1]) = 0xffffffff;
   *((int*)& __m128_op0[0]) = 0xffffff00;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffffffffff00;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffffff00;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xffffffff;
+  *((int*)& __m128_result[2]) = 0xffffff00;
+  *((int*)& __m128_result[1]) = 0xffffffff;
+  *((int*)& __m128_result[0]) = 0xffffff00;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x7ff0000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x7ff0000000000000;
@@ -70895,12 +70981,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x8011ffee804c004c;
   *((unsigned long*)& __m256i_op0[2]) = 0x00faff0500c3ff3c;
@@ -71113,12 +71203,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0fff0fff0fff0fff;
   *((unsigned long*)& __m128i_op0[0]) = 0x0fff0fff0fff0fff;
@@ -72125,10 +72215,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x856ba83b;
   *((int*)& __m128_op0[1]) = 0x8003caef;
   *((int*)& __m128_op0[0]) = 0x54691124;
-  *((unsigned long*)& __m128i_result[1]) = 0xbf800000bf800000;
-  *((unsigned long*)& __m128i_result[0]) = 0xbf80000054691124;
-  __m128i_out = __lsx_vfrintrm_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xbf800000;
+  *((int*)& __m128_result[2]) = 0xbf800000;
+  *((int*)& __m128_result[1]) = 0xbf800000;
+  *((int*)& __m128_result[0]) = 0x54691124;
+  __m128_out = __lsx_vfrintrm_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((int*)& __m256_op0[7]) = 0xfff0fff0;
   *((int*)& __m256_op0[6]) = 0xff01ff01;
@@ -72370,10 +72462,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0xffff57c9;
   *((int*)& __m128_op0[1]) = 0xffff6080;
   *((int*)& __m128_op0[0]) = 0xffff4417;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffb96bffff57c9;
-  *((unsigned long*)& __m128i_result[0]) = 0xffff6080ffff4417;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xffffb96b;
+  *((int*)& __m128_result[2]) = 0xffff57c9;
+  *((int*)& __m128_result[1]) = 0xffff6080;
+  *((int*)& __m128_result[0]) = 0xffff4417;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((int*)& __m128_op0[3]) = 0x000000ad;
   *((int*)& __m128_op0[2]) = 0x00007081;
@@ -74496,10 +74590,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x4acfaf40;
   *((int*)& __m128_op0[1]) = 0xf0bc9a52;
   *((int*)& __m128_op0[0]) = 0x78285a4a;
-  *((unsigned long*)& __m128i_result[1]) = 0x62cbf96e4acfaf40;
-  *((unsigned long*)& __m128i_result[0]) = 0xf0bc9a5278285a4a;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x62cbf96e;
+  *((int*)& __m128_result[2]) = 0x4acfaf40;
+  *((int*)& __m128_result[1]) = 0xf0bc9a52;
+  *((int*)& __m128_result[0]) = 0x78285a4a;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xfffffacdb6dbecac;
   *((unsigned long*)& __m128i_op0[0]) = 0x1f5533a694f902c0;
@@ -74760,10 +74856,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00ff00ff;
   *((int*)& __m128_op0[1]) = 0x62cbf96e;
   *((int*)& __m128_op0[0]) = 0x4acfaf40;
-  *((unsigned long*)& __m128i_result[1]) = 0x3f8000003f800000;
-  *((unsigned long*)& __m128i_result[0]) = 0x62cbf96e4acfaf40;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x3f800000;
+  *((int*)& __m128_result[2]) = 0x3f800000;
+  *((int*)& __m128_result[1]) = 0x62cbf96e;
+  *((int*)& __m128_result[0]) = 0x4acfaf40;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -74861,10 +74959,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x01f50000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((int*)& __m128_op0[3]) = 0x00000000;
   *((int*)& __m128_op0[2]) = 0x00000000;
@@ -76224,10 +76324,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -77035,12 +77135,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000080008001;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000080008001;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   int_op0 = 0x0000000000000000;
   *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
@@ -78197,12 +78297,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x5d20a0a1;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x5d20a0a15d20a0a1;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x5d20a0a15d20a0a1;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x5d20a0a1;
+  *((int*)& __m256_result[6]) = 0x5d20a0a1;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x5d20a0a1;
+  *((int*)& __m256_result[2]) = 0x5d20a0a1;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -78953,10 +79057,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00002000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x1fe02000;
-  *((unsigned long*)& __m128i_result[1]) = 0x000000003f800000;
-  *((unsigned long*)& __m128i_result[0]) = 0x000000003f800000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x3f800000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x3f800000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000040;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000040;
@@ -79175,12 +79281,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x371fe00000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x371fe00000000000;
@@ -79502,12 +79612,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x7ff0000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x7ff0000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x7ff0000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x7ff0000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x7ff0000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x7ff0000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x7ff0000000000000;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x7ff0000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x7ff0000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x7ff0000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x7ff0000000000000;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffffffffffffff;
@@ -81602,10 +81712,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x8000800080008000;
   *((unsigned long*)& __m256i_op0[2]) = 0x8000800080008000;
@@ -83342,12 +83452,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xffffffff;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xffffffff;
+  *((int*)& __m256_result[6]) = 0xffffffff;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0xffffffff;
+  *((int*)& __m256_result[2]) = 0xffffffff;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrne_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0003c853c843c87e;
   *((unsigned long*)& __m128i_op0[0]) = 0x0003c853c843c87e;
@@ -86710,10 +86824,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0xffffffff;
   *((int*)& __m128_op0[1]) = 0xffffffff;
   *((int*)& __m128_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffffffff;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xffffffff;
+  *((int*)& __m128_result[2]) = 0xffffffff;
+  *((int*)& __m128_result[1]) = 0xffffffff;
+  *((int*)& __m128_result[0]) = 0xffffffff;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x8000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0xfff0000000000000;
@@ -87148,10 +87264,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000080800000808;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000080800000808;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
@@ -88694,10 +88810,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0x00000000ff801c9e;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000810000;
@@ -90217,12 +90335,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x001d001d;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0x0000000000000003;
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000010001;
@@ -90469,12 +90591,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x7c00000880008000;
   *((unsigned long*)& __m256d_op0[1]) = 0x00000000ffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0x7c00000880008000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x7c00000880008000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x7c00000880008000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x7c00000880008000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x7c00000880008000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x00000000ffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0x7c00000880008000;
@@ -91584,10 +91706,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -92116,12 +92240,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000033;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x3fc03fc000000003;
   *((unsigned long*)& __m128i_op0[0]) = 0x7f7f1fd800000004;
@@ -92231,10 +92359,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m128d_op0[0]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffffffff;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m128d_result[0]) = 0xffffffffffffffff;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x7f801fe000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x3fc03fc000000004;
@@ -92876,12 +93004,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000ffff00000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -93856,10 +93984,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((int*)& __m128_op0[3]) = 0x00000000;
   *((int*)& __m128_op0[2]) = 0x00000000;
@@ -93901,12 +94029,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xfc00000000000048;
   *((unsigned long*)& __m256d_op0[1]) = 0x0218ff78fc38fc38;
   *((unsigned long*)& __m256d_op0[0]) = 0xfc00000000000048;
-  *((unsigned long*)& __m256i_result[3]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0xfc00000000000048;
-  *((unsigned long*)& __m256i_result[1]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0xfc00000000000048;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0xfc00000000000048;
+  *((unsigned long*)& __m256d_result[1]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0xfc00000000000048;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((int*)& __m256_op0[7]) = 0x00000000;
   *((int*)& __m256_op0[6]) = 0x00000000;
@@ -94443,10 +94571,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -94639,17 +94769,17 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x00000000ffe36780;
   *((unsigned long*)& __m256i_op0[2]) = 0x8000000100000001;
@@ -94855,12 +94985,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000010100000101;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000010100000101;
@@ -95612,12 +95742,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000001;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -97237,12 +97371,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -97300,12 +97434,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000064;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000781;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000064;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((int*)& __m128_op0[3]) = 0x0c0b0a09;
   *((int*)& __m128_op0[2]) = 0x0b0a0908;
@@ -97339,12 +97473,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000fffe00006aea;
@@ -97459,10 +97597,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00010002;
   *((int*)& __m128_op0[1]) = 0xffffffff;
   *((int*)& __m128_op0[0]) = 0xff960015;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffd60015;
-  __m128i_out = __lsx_vfrintrm_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0xffffffff;
+  *((int*)& __m128_result[0]) = 0xffd60015;
+  __m128_out = __lsx_vfrintrm_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffd60015;
@@ -99605,10 +99745,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0xffffffff;
   *((int*)& __m128_op0[1]) = 0xffffffff;
   *((int*)& __m128_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffffffff;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xffffffff;
+  *((int*)& __m128_result[2]) = 0xffffffff;
+  *((int*)& __m128_result[1]) = 0xffffffff;
+  *((int*)& __m128_result[0]) = 0xffffffff;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffffff;
@@ -99831,12 +99973,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x41dfffffffc00000;
   *((unsigned long*)& __m256i_op0[2]) = 0xc1d75053f0000000;
@@ -102116,12 +102258,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0010000100000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0010000100000000;
@@ -102558,10 +102704,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000001;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000001;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000200000002;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000200000002;
@@ -104219,10 +104367,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrm_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -104237,12 +104387,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x001fe020001fe020;
   *((unsigned long*)& __m256d_op0[1]) = 0x000000001ffe2000;
   *((unsigned long*)& __m256d_op0[0]) = 0x001fe020001fe020;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -104875,10 +105025,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x7efefefe82010201;
@@ -105855,10 +106005,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m128d_op0[0]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m128i_result[0]) = 0xffffffffffffffff;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m128d_result[0]) = 0xffffffffffffffff;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -107531,12 +107681,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0001000100010058;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -108011,10 +108161,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x000000007f7f7f80;
@@ -108989,12 +109141,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x8000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x8000000000000000;
@@ -109359,12 +109511,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrm_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x00000000fffff800;
@@ -111953,10 +112105,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000400028000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000004;
@@ -112192,10 +112346,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrz_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x007f0000007f0060;
@@ -112404,10 +112560,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffffff;
@@ -112617,12 +112773,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xffffffff;
   *((int*)& __m256_op0[1]) = 0xffffffff;
   *((int*)& __m256_op0[0]) = 0xffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrne_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xffffffff;
+  *((int*)& __m256_result[6]) = 0xffffffff;
+  *((int*)& __m256_result[5]) = 0xffffffff;
+  *((int*)& __m256_result[4]) = 0xffffffff;
+  *((int*)& __m256_result[3]) = 0xffffffff;
+  *((int*)& __m256_result[2]) = 0xffffffff;
+  *((int*)& __m256_result[1]) = 0xffffffff;
+  *((int*)& __m256_result[0]) = 0xffffffff;
+  __m256_out = __lasx_xvfrintrne_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffffff;
@@ -113023,10 +113183,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000007f00ff00ff;
   *((unsigned long*)& __m128d_op0[0]) = 0x00ff00ff00ff00ff;
-  *((unsigned long*)& __m128i_result[1]) = 0x3ff0000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x3ff0000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x3ff0000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x3ff0000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -114514,12 +114674,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -115084,12 +115244,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -115191,12 +115355,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -117238,10 +117402,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -117743,12 +117907,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x6040190d00000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x6018000000000cd1;
   *((unsigned long*)& __m256d_op0[0]) = 0x6040190d00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x6018000000000cd1;
-  *((unsigned long*)& __m256i_result[2]) = 0x6040190d00000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x6018000000000cd1;
-  *((unsigned long*)& __m256i_result[0]) = 0x6040190d00000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x6018000000000cd1;
+  *((unsigned long*)& __m256d_result[2]) = 0x6040190d00000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x6018000000000cd1;
+  *((unsigned long*)& __m256d_result[0]) = 0x6040190d00000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((int*)& __m128_op0[3]) = 0x00000000;
   *((int*)& __m128_op0[2]) = 0x00000000;
@@ -119005,12 +119169,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x408480007fff0000;
   *((unsigned long*)& __m256d_op0[1]) = 0x3eab77367fff4848;
   *((unsigned long*)& __m256d_op0[0]) = 0x408480007fff0000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x4084800000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x4084800000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x4084800000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x4084800000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[2]) = 0xffffffffffffffff;
@@ -119156,12 +119320,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xffff0001ffff0001;
   *((unsigned long*)& __m256d_op0[1]) = 0xffff0001ffff0001;
   *((unsigned long*)& __m256d_op0[0]) = 0xffff0001ffff0001;
-  *((unsigned long*)& __m256i_result[3]) = 0xffff0001ffff0001;
-  *((unsigned long*)& __m256i_result[2]) = 0xffff0001ffff0001;
-  *((unsigned long*)& __m256i_result[1]) = 0xffff0001ffff0001;
-  *((unsigned long*)& __m256i_result[0]) = 0xffff0001ffff0001;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffff0001ffff0001;
+  *((unsigned long*)& __m256d_result[2]) = 0xffff0001ffff0001;
+  *((unsigned long*)& __m256d_result[1]) = 0xffff0001ffff0001;
+  *((unsigned long*)& __m256d_result[0]) = 0xffff0001ffff0001;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x3eab77367fff4848;
   *((unsigned long*)& __m256i_op0[2]) = 0x408480007fff0000;
@@ -119457,12 +119621,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x01610000;
   *((int*)& __m256_op0[1]) = 0x00612000;
   *((int*)& __m256_op0[0]) = 0x00610000;
-  *((unsigned long*)& __m256i_result[3]) = 0x3f8000003f800000;
-  *((unsigned long*)& __m256i_result[2]) = 0x3f8000003f800000;
-  *((unsigned long*)& __m256i_result[1]) = 0x3f8000003f800000;
-  *((unsigned long*)& __m256i_result[0]) = 0x3f8000003f800000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x3f800000;
+  *((int*)& __m256_result[6]) = 0x3f800000;
+  *((int*)& __m256_result[5]) = 0x3f800000;
+  *((int*)& __m256_result[4]) = 0x3f800000;
+  *((int*)& __m256_result[3]) = 0x3f800000;
+  *((int*)& __m256_result[2]) = 0x3f800000;
+  *((int*)& __m256_result[1]) = 0x3f800000;
+  *((int*)& __m256_result[0]) = 0x3f800000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -120241,12 +120409,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000008;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000008;
@@ -120390,10 +120558,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0xffffffff02000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x1f81e3779b97f4a8;
-  *((unsigned long*)& __m128i_result[1]) = 0xffffffff02000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0xffffffff02000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((int*)& __m128_op0[3]) = 0x00000000;
   *((int*)& __m128_op0[2]) = 0x00000014;
@@ -122109,12 +122277,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
@@ -123377,12 +123549,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -125068,12 +125244,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -125865,12 +126045,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x00004000007f8000;
   *((unsigned long*)& __m256d_op0[1]) = 0x3fffbfff80000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x00004000007f8000;
-  *((unsigned long*)& __m256i_result[3]) = 0x4000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x4000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x4000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x4000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x680485c8b304b019;
   *((unsigned long*)& __m128i_op0[0]) = 0xc89d7f0fed582019;
@@ -125894,12 +126074,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x8000800080008000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x8000800080008000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x8000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x8000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x8000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x8000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x000000003ddc5dac;
@@ -126732,10 +126912,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -128505,12 +128687,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0xfefefefe;
   *((int*)& __m256_op0[0]) = 0x01010101;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0xfefefefe3f800000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0xfefefefe3f800000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0xfefefefe;
+  *((int*)& __m256_result[4]) = 0x3f800000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0xfefefefe;
+  *((int*)& __m256_result[0]) = 0x3f800000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -129720,10 +129906,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrm_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -129814,12 +130002,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -130722,10 +130910,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -131295,12 +131485,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((int*)& __m128_op0[3]) = 0xffffffff;
   *((int*)& __m128_op0[2]) = 0xffffffff;
@@ -132564,12 +132758,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x00000000ffffffff;
@@ -136404,10 +136598,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000001;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -136623,10 +136817,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffff8000;
   *((unsigned long*)& __m256i_op0[2]) = 0x7efefefe80ffffff;
@@ -136723,12 +136917,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xffffffffffff8000;
   *((unsigned long*)& __m256i_op0[2]) = 0x7efefefe80ffffff;
@@ -136916,12 +137110,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x00000000;
   *((int*)& __m256_op0[1]) = 0x00000000;
   *((int*)& __m256_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrm_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrm_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x00000000ffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -137059,10 +137257,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -137247,12 +137447,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m256d_op0[0]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[3]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[2]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[1]) = 0xffffffffffffffff;
-  *((unsigned long*)& __m256i_result[0]) = 0xffffffffffffffff;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[2]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[1]) = 0xffffffffffffffff;
+  *((unsigned long*)& __m256d_result[0]) = 0xffffffffffffffff;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -137458,10 +137658,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x00000000ffffffff;
@@ -139712,10 +139912,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000004;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x8000000080000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x8000000080000000;
@@ -140322,10 +140522,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00020004;
   *((int*)& __m128_op0[0]) = 0x00000001;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0xffffffffffffffff;
   *((unsigned long*)& __m128i_op0[0]) = 0xffffffffffffffff;
@@ -140835,10 +141037,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0xf2f444429d96dbe1;
   *((unsigned long*)& __m128d_op0[0]) = 0xddd76c75f2f44442;
@@ -141970,10 +142172,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x00000000abba7980;
   *((unsigned long*)& __m128d_op0[0]) = 0x00000000ccf98000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   int_op0 = 0x0000000000000000;
   *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
@@ -142241,10 +142443,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x00000000;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0x00000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0x00000000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x0000000000000000;
@@ -142792,10 +142996,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0xfffbfffb;
   *((int*)& __m128_op0[1]) = 0xfffbfffb;
   *((int*)& __m128_op0[0]) = 0xfffbfffb;
-  *((unsigned long*)& __m128i_result[1]) = 0xfffbfffbfffbfffb;
-  *((unsigned long*)& __m128i_result[0]) = 0xfffbfffbfffbfffb;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0xfffbfffb;
+  *((int*)& __m128_result[2]) = 0xfffbfffb;
+  *((int*)& __m128_result[1]) = 0xfffbfffb;
+  *((int*)& __m128_result[0]) = 0xfffbfffb;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((int*)& __m256_op0[7]) = 0xffffffff;
   *((int*)& __m256_op0[6]) = 0xffffffff;
@@ -143441,10 +143647,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000868686868686;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0xff1cff1cff1cff1c;
   *((unsigned long*)& __m256i_op0[2]) = 0xff1cff1cff1cff1c;
@@ -144417,10 +144623,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000077af9450;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x3ff0000000000000;
-  __m128i_out = __lsx_vfrintrp_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x3ff0000000000000;
+  __m128d_out = __lsx_vfrintrp_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x00007fff7fff8000;
@@ -144538,12 +144744,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0101010101010101;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrz_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrz_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0000000000000000;
   *((unsigned long*)& __m256i_op0[2]) = 0x00000000000d6d6d;
@@ -145992,10 +146198,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0001000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0001000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrm_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrm_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x41dffbffffffffff;
   *((unsigned long*)& __m256i_op0[2]) = 0xffffff00ff800000;
@@ -147073,10 +147279,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0xfe3bfb01fe3bfe01;
   *((unsigned long*)& __m128d_op0[0]) = 0xfe03fe3ffe01fa21;
-  *((unsigned long*)& __m128i_result[1]) = 0xfe3bfb01fe3bfe01;
-  *((unsigned long*)& __m128i_result[0]) = 0xfe03fe3ffe01fa21;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0xfe3bfb01fe3bfe01;
+  *((unsigned long*)& __m128d_result[0]) = 0xfe03fe3ffe01fa21;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0x1c1c1c1c1c1c1c1c;
   *((unsigned long*)& __m256d_op0[2]) = 0xffffffffffffffff;
@@ -147440,12 +147646,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x1c1c1c1c;
   *((int*)& __m256_op0[1]) = 0xfffffffe;
   *((int*)& __m256_op0[0]) = 0xffffff00;
-  *((unsigned long*)& __m256i_result[3]) = 0x3f8000003f800000;
-  *((unsigned long*)& __m256i_result[2]) = 0xfffffffeffffff00;
-  *((unsigned long*)& __m256i_result[1]) = 0x3f8000003f800000;
-  *((unsigned long*)& __m256i_result[0]) = 0xfffffffeffffff00;
-  __m256i_out = __lasx_xvfrintrp_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x3f800000;
+  *((int*)& __m256_result[6]) = 0x3f800000;
+  *((int*)& __m256_result[5]) = 0xfffffffe;
+  *((int*)& __m256_result[4]) = 0xffffff00;
+  *((int*)& __m256_result[3]) = 0x3f800000;
+  *((int*)& __m256_result[2]) = 0x3f800000;
+  *((int*)& __m256_result[1]) = 0xfffffffe;
+  *((int*)& __m256_result[0]) = 0xffffff00;
+  __m256_out = __lasx_xvfrintrp_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((int*)& __m128_op0[3]) = 0xffffffff;
   *((int*)& __m128_op0[2]) = 0xffffffff;
@@ -149087,12 +149297,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0xfffffff0fffffff0;
   *((unsigned long*)& __m256d_op0[1]) = 0xfffffff0fffffff0;
   *((unsigned long*)& __m256d_op0[0]) = 0xfffffff0fffffff0;
-  *((unsigned long*)& __m256i_result[3]) = 0xfffffff0fffffff0;
-  *((unsigned long*)& __m256i_result[2]) = 0xfffffff0fffffff0;
-  *((unsigned long*)& __m256i_result[1]) = 0xfffffff0fffffff0;
-  *((unsigned long*)& __m256i_result[0]) = 0xfffffff0fffffff0;
-  __m256i_out = __lasx_xvfrintrp_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0xfffffff0fffffff0;
+  *((unsigned long*)& __m256d_result[2]) = 0xfffffff0fffffff0;
+  *((unsigned long*)& __m256d_result[1]) = 0xfffffff0fffffff0;
+  *((unsigned long*)& __m256d_result[0]) = 0xfffffff0fffffff0;
+  __m256d_out = __lasx_xvfrintrp_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
@@ -149397,10 +149607,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x63abdf16;
   *((int*)& __m128_op0[1]) = 0x41f8e080;
   *((int*)& __m128_op0[0]) = 0x16161198;
-  *((unsigned long*)& __m128i_result[1]) = 0x6363636363abdf16;
-  *((unsigned long*)& __m128i_result[0]) = 0x420000003f800000;
-  __m128i_out = __lsx_vfrintrp_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x63636363;
+  *((int*)& __m128_result[2]) = 0x63abdf16;
+  *((int*)& __m128_result[1]) = 0x42000000;
+  *((int*)& __m128_result[0]) = 0x3f800000;
+  __m128_out = __lsx_vfrintrp_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000feff23560000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000fd1654860000;
@@ -149604,19 +149816,23 @@ int main() {
   *((int*)& __m256_op0[2]) = 0x01010101;
   *((int*)& __m256_op0[1]) = 0x01010101;
   *((int*)& __m256_op0[0]) = 0x00000001;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0x00000000;
+  *((int*)& __m256_result[6]) = 0x00000000;
+  *((int*)& __m256_result[5]) = 0x00000000;
+  *((int*)& __m256_result[4]) = 0x00000000;
+  *((int*)& __m256_result[3]) = 0x00000000;
+  *((int*)& __m256_result[2]) = 0x00000000;
+  *((int*)& __m256_result[1]) = 0x00000000;
+  *((int*)& __m256_result[0]) = 0x00000000;
+  __m256_out = __lasx_xvfrintrne_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m128d_op0[1]) = 0x5847b72626ce61ef;
   *((unsigned long*)& __m128d_op0[0]) = 0x110053f401e7cced;
-  *((unsigned long*)& __m128i_result[1]) = 0x5847b72626ce61ef;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrz_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x5847b72626ce61ef;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrz_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m256i_op0[3]) = 0x0101010101010101;
   *((unsigned long*)& __m256i_op0[2]) = 0x0101010100000001;
@@ -152193,12 +152409,16 @@ int main() {
   *((int*)& __m256_op0[2]) = 0xfc000000;
   *((int*)& __m256_op0[1]) = 0xf5fffc00;
   *((int*)& __m256_op0[0]) = 0xfc000000;
-  *((unsigned long*)& __m256i_result[3]) = 0xf5fffc00fc000000;
-  *((unsigned long*)& __m256i_result[2]) = 0xf5fffc00fc000000;
-  *((unsigned long*)& __m256i_result[1]) = 0xf5fffc00fc000000;
-  *((unsigned long*)& __m256i_result[0]) = 0xf5fffc00fc000000;
-  __m256i_out = __lasx_xvfrintrz_s(__m256_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((int*)& __m256_result[7]) = 0xf5fffc00;
+  *((int*)& __m256_result[6]) = 0xfc000000;
+  *((int*)& __m256_result[5]) = 0xf5fffc00;
+  *((int*)& __m256_result[4]) = 0xfc000000;
+  *((int*)& __m256_result[3]) = 0xf5fffc00;
+  *((int*)& __m256_result[2]) = 0xfc000000;
+  *((int*)& __m256_result[1]) = 0xf5fffc00;
+  *((int*)& __m256_result[0]) = 0xfc000000;
+  __m256_out = __lasx_xvfrintrz_s(__m256_op0);
+  ASSERTEQ_64(__LINE__, __m256_result, __m256_out);
 
   *((unsigned long*)& __m256d_op0[3]) = 0x00000005ffffffff;
   *((unsigned long*)& __m256d_op0[2]) = 0x00000007ffffffce;
@@ -154202,10 +154422,12 @@ int main() {
   *((int*)& __m128_op0[2]) = 0x0efc01af;
   *((int*)& __m128_op0[1]) = 0x00000000;
   *((int*)& __m128_op0[0]) = 0xfe7f0000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x00000000fe7f0000;
-  __m128i_out = __lsx_vfrintrne_s(__m128_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((int*)& __m128_result[3]) = 0x00000000;
+  *((int*)& __m128_result[2]) = 0x00000000;
+  *((int*)& __m128_result[1]) = 0x00000000;
+  *((int*)& __m128_result[0]) = 0xfe7f0000;
+  __m128_out = __lsx_vfrintrne_s(__m128_op0);
+  ASSERTEQ_64(__LINE__, __m128_result, __m128_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x087c000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x000000000000087c;
@@ -154777,12 +154999,12 @@ int main() {
   *((unsigned long*)& __m256d_op0[2]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m256d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[3]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[2]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m256i_result[0]) = 0x0000000000000000;
-  __m256i_out = __lasx_xvfrintrne_d(__m256d_op0);
-  ASSERTEQ_64(__LINE__, __m256i_result, __m256i_out);
+  *((unsigned long*)& __m256d_result[3]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[2]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m256d_result[0]) = 0x0000000000000000;
+  __m256d_out = __lasx_xvfrintrne_d(__m256d_op0);
+  ASSERTEQ_64(__LINE__, __m256d_result, __m256d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0001000100010012;
   *((unsigned long*)& __m128i_op0[0]) = 0x00000000fec20704;
@@ -155971,10 +156193,10 @@ int main() {
 
   *((unsigned long*)& __m128d_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128d_op0[0]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[1]) = 0x0000000000000000;
-  *((unsigned long*)& __m128i_result[0]) = 0x0000000000000000;
-  __m128i_out = __lsx_vfrintrne_d(__m128d_op0);
-  ASSERTEQ_64(__LINE__, __m128i_result, __m128i_out);
+  *((unsigned long*)& __m128d_result[1]) = 0x0000000000000000;
+  *((unsigned long*)& __m128d_result[0]) = 0x0000000000000000;
+  __m128d_out = __lsx_vfrintrne_d(__m128d_op0);
+  ASSERTEQ_64(__LINE__, __m128d_result, __m128d_out);
 
   *((unsigned long*)& __m128i_op0[1]) = 0x0000000000000000;
   *((unsigned long*)& __m128i_op0[0]) = 0x0000000000000000;
diff --git a/gcc/testsuite/gcc.target/loongarch/lasx-builtin.c b/gcc/testsuite/gcc.target/loongarch/lasx-builtin.c
index 1f563ec81..ecb8d639b 100644
--- a/gcc/testsuite/gcc.target/loongarch/lasx-builtin.c
+++ b/gcc/testsuite/gcc.target/loongarch/lasx-builtin.c
@@ -1227,14 +1227,14 @@ v4i64 __lasx_xvftintrmh_l_s(v8f32 _1){return __builtin_lasx_xvftintrmh_l_s(_1);}
 v4i64 __lasx_xvftintrml_l_s(v8f32 _1){return __builtin_lasx_xvftintrml_l_s(_1);}
 v4i64 __lasx_xvftintrneh_l_s(v8f32 _1){return __builtin_lasx_xvftintrneh_l_s(_1);}
 v4i64 __lasx_xvftintrnel_l_s(v8f32 _1){return __builtin_lasx_xvftintrnel_l_s(_1);}
-v8i32 __lasx_xvfrintrne_s(v8f32 _1){return __builtin_lasx_xvfrintrne_s(_1);}
-v4i64 __lasx_xvfrintrne_d(v4f64 _1){return __builtin_lasx_xvfrintrne_d(_1);}
-v8i32 __lasx_xvfrintrz_s(v8f32 _1){return __builtin_lasx_xvfrintrz_s(_1);}
-v4i64 __lasx_xvfrintrz_d(v4f64 _1){return __builtin_lasx_xvfrintrz_d(_1);}
-v8i32 __lasx_xvfrintrp_s(v8f32 _1){return __builtin_lasx_xvfrintrp_s(_1);}
-v4i64 __lasx_xvfrintrp_d(v4f64 _1){return __builtin_lasx_xvfrintrp_d(_1);}
-v8i32 __lasx_xvfrintrm_s(v8f32 _1){return __builtin_lasx_xvfrintrm_s(_1);}
-v4i64 __lasx_xvfrintrm_d(v4f64 _1){return __builtin_lasx_xvfrintrm_d(_1);}
+v8f32 __lasx_xvfrintrne_s(v8f32 _1){return __builtin_lasx_xvfrintrne_s(_1);}
+v4f64 __lasx_xvfrintrne_d(v4f64 _1){return __builtin_lasx_xvfrintrne_d(_1);}
+v8f32 __lasx_xvfrintrz_s(v8f32 _1){return __builtin_lasx_xvfrintrz_s(_1);}
+v4f64 __lasx_xvfrintrz_d(v4f64 _1){return __builtin_lasx_xvfrintrz_d(_1);}
+v8f32 __lasx_xvfrintrp_s(v8f32 _1){return __builtin_lasx_xvfrintrp_s(_1);}
+v4f64 __lasx_xvfrintrp_d(v4f64 _1){return __builtin_lasx_xvfrintrp_d(_1);}
+v8f32 __lasx_xvfrintrm_s(v8f32 _1){return __builtin_lasx_xvfrintrm_s(_1);}
+v4f64 __lasx_xvfrintrm_d(v4f64 _1){return __builtin_lasx_xvfrintrm_d(_1);}
 v32i8 __lasx_xvld(void * _1){return __builtin_lasx_xvld(_1, 1);}
 void __lasx_xvst(v32i8 _1, void * _2){return __builtin_lasx_xvst(_1, _2, 1);}
 void __lasx_xvstelm_b(v32i8 _1, void * _2){return __builtin_lasx_xvstelm_b(_1, _2, 1, 1);}
diff --git a/gcc/testsuite/gcc.target/loongarch/lsx-builtin.c b/gcc/testsuite/gcc.target/loongarch/lsx-builtin.c
index 296869dc5..70f5000b2 100644
--- a/gcc/testsuite/gcc.target/loongarch/lsx-builtin.c
+++ b/gcc/testsuite/gcc.target/loongarch/lsx-builtin.c
@@ -1209,14 +1209,14 @@ v2i64 __lsx_vftintrml_l_s(v4f32 _1){return __builtin_lsx_vftintrml_l_s(_1);}
 v2i64 __lsx_vftintrmh_l_s(v4f32 _1){return __builtin_lsx_vftintrmh_l_s(_1);}
 v2i64 __lsx_vftintrnel_l_s(v4f32 _1){return __builtin_lsx_vftintrnel_l_s(_1);}
 v2i64 __lsx_vftintrneh_l_s(v4f32 _1){return __builtin_lsx_vftintrneh_l_s(_1);}
-v4i32 __lsx_vfrintrne_s(v4f32 _1){return __builtin_lsx_vfrintrne_s(_1);}
-v2i64 __lsx_vfrintrne_d(v2f64 _1){return __builtin_lsx_vfrintrne_d(_1);}
-v4i32 __lsx_vfrintrz_s(v4f32 _1){return __builtin_lsx_vfrintrz_s(_1);}
-v2i64 __lsx_vfrintrz_d(v2f64 _1){return __builtin_lsx_vfrintrz_d(_1);}
-v4i32 __lsx_vfrintrp_s(v4f32 _1){return __builtin_lsx_vfrintrp_s(_1);}
-v2i64 __lsx_vfrintrp_d(v2f64 _1){return __builtin_lsx_vfrintrp_d(_1);}
-v4i32 __lsx_vfrintrm_s(v4f32 _1){return __builtin_lsx_vfrintrm_s(_1);}
-v2i64 __lsx_vfrintrm_d(v2f64 _1){return __builtin_lsx_vfrintrm_d(_1);}
+v4f32 __lsx_vfrintrne_s(v4f32 _1){return __builtin_lsx_vfrintrne_s(_1);}
+v2f64 __lsx_vfrintrne_d(v2f64 _1){return __builtin_lsx_vfrintrne_d(_1);}
+v4f32 __lsx_vfrintrz_s(v4f32 _1){return __builtin_lsx_vfrintrz_s(_1);}
+v2f64 __lsx_vfrintrz_d(v2f64 _1){return __builtin_lsx_vfrintrz_d(_1);}
+v4f32 __lsx_vfrintrp_s(v4f32 _1){return __builtin_lsx_vfrintrp_s(_1);}
+v2f64 __lsx_vfrintrp_d(v2f64 _1){return __builtin_lsx_vfrintrp_d(_1);}
+v4f32 __lsx_vfrintrm_s(v4f32 _1){return __builtin_lsx_vfrintrm_s(_1);}
+v2f64 __lsx_vfrintrm_d(v2f64 _1){return __builtin_lsx_vfrintrm_d(_1);}
 void __lsx_vstelm_b(v16i8 _1, void * _2){return __builtin_lsx_vstelm_b(_1, _2, 1, 1);}
 void __lsx_vstelm_h(v8i16 _1, void * _2){return __builtin_lsx_vstelm_h(_1, _2, 2, 1);}
 void __lsx_vstelm_w(v4i32 _1, void * _2){return __builtin_lsx_vstelm_w(_1, _2, 4, 1);}
diff --git a/gcc/testsuite/gcc.target/loongarch/mulh.c b/gcc/testsuite/gcc.target/loongarch/mulh.c
new file mode 100644
index 000000000..bef35828d
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/mulh.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "mulh.wu" } } */
+
+typedef unsigned int DI __attribute__((mode(DI)));
+typedef unsigned int SI __attribute__((mode(SI)));
+
+SI
+f (SI x, SI y)
+{
+  return ((DI) x * y) >> 32;
+}
+
diff --git a/gcc/testsuite/gcc.target/loongarch/mulw_d.c b/gcc/testsuite/gcc.target/loongarch/mulw_d.c
new file mode 100644
index 000000000..db8c0d867
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/mulw_d.c
@@ -0,0 +1,13 @@
+/* { dg-do compile } */
+/* { dg-options "-O2" } */
+/* { dg-final { scan-assembler "mulw.d.wu" } } */
+
+typedef unsigned int DI __attribute__((mode(DI)));
+typedef unsigned int SI __attribute__((mode(SI)));
+
+DI
+f (SI x, SI y)
+{
+  return (DI) x * y;
+}
+
diff --git a/gcc/testsuite/gcc.target/loongarch/vec-unpack.c b/gcc/testsuite/gcc.target/loongarch/vec-unpack.c
new file mode 100644
index 000000000..a7fa86519
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/vec-unpack.c
@@ -0,0 +1,18 @@
+/* { dg-do compile } */
+/* { dg-options "-O3 -mlasx" } */
+/* { dg-final { scan-assembler-times "xvpermi.d" 2} } */
+/* { dg-final { scan-assembler-times "xvfcvtl.d.s" 2} } */
+/* { dg-final { scan-assembler-times "xvfcvth.d.s" 2} } */
+
+#define N 16                                              
+float f[N];
+double d[N];
+int n[N];
+
+__attribute__((noinline)) void
+foo (void)
+{
+  int i;
+  for (i = 0; i < N; i++)
+    d[i] = f[i];
+}
diff --git a/gcc/testsuite/gcc.target/loongarch/vec_initv32qiv16qi.c b/gcc/testsuite/gcc.target/loongarch/vec_initv32qiv16qi.c
new file mode 100644
index 000000000..84e57645a
--- /dev/null
+++ b/gcc/testsuite/gcc.target/loongarch/vec_initv32qiv16qi.c
@@ -0,0 +1,23 @@
+/* { dg-do compile } */
+/* { dg-options "-mlasx -O3 -ftree-vectorize -fdump-tree-vect-details" } */
+
+typedef unsigned char uint8_t;
+
+int
+test_func (uint8_t *pix1, int i_stride_pix1,
+	   uint8_t *pix2, int i_stride_pix2)
+{
+    int i_sum = 0;
+    for (int y = 0; y < 16; y++)
+      {
+        for (int x = 0; x < 16; x++)
+	  {
+            i_sum += __builtin_abs (pix1[x] - pix2[x]);
+	  }
+        pix1 += i_stride_pix1;
+        pix2 += i_stride_pix2;
+      }
+    return i_sum;
+}
+
+/* { dg-final { scan-tree-dump "vect_cst__438 = {_442, _440}" "vect" } } */
diff --git a/libgcc/config.host b/libgcc/config.host
index 1326c8882..8fd11febd 100644
--- a/libgcc/config.host
+++ b/libgcc/config.host
@@ -974,18 +974,14 @@ mips*-sde-elf*)
 	esac
 	extra_parts="$extra_parts crti.o crtn.o"
 	;;
-loongarch*-sde-elf*)
-	tmake_file="$tmake_file loongarch/t-crtstuff"
-	case "${with_newlib}" in
-	  yes)
-	    # newlib / libgloss.
-	    ;;
+loongarch64-*-elf*)
+	extra_parts="$extra_parts crtfastmath.o"
+	tmake_file="${tmake_file} t-crtfm loongarch/t-crtstuff"
+	case ${host} in
 	  *)
-	    # MIPS toolkit libraries.
-	    tmake_file="$tmake_file loongarch/t-sdemtk"
+	    tmake_file="${tmake_file} t-slibgcc-libgcc"
 	    ;;
 	esac
-	extra_parts="$extra_parts crti.o crtn.o"
 	;;
 mipsisa32-*-elf* | mipsisa32el-*-elf* | \
 mipsisa32r2-*-elf* | mipsisa32r2el-*-elf* | \
